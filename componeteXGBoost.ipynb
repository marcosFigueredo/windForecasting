{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9a3b67",
   "metadata": {},
   "source": [
    "## Componentes XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24a1ca93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≤ TREINAMENTO XGBOOST SIMPLES\n",
      "==================================================\n",
      "üìã Fun√ß√µes dispon√≠veis:\n",
      "\n",
      "üîπ treinar_xgboost_componente('d1', passo=1)\n",
      "   ‚Üí Treina um modelo espec√≠fico\n",
      "\n",
      "üîπ treinar_todos_componentes([1, 5, 7, 30])\n",
      "   ‚Üí Treina todos os modelos para todos os horizontes\n",
      "\n",
      "üí° CARACTER√çSTICAS DOS MODELOS:\n",
      "   ‚Ä¢ Apenas sequ√™ncias temporais (sem features)\n",
      "   ‚Ä¢ Look_back: 5 para t+1,t+5 | 10 para demais\n",
      "   ‚Ä¢ Scaler: RobustScaler\n",
      "   ‚Ä¢ Modelo: XGBRegressor\n",
      "   ‚Ä¢ Consistente com LSTM (apenas sequ√™ncias)\n",
      "\n",
      "üéØ EXEMPLO DE USO:\n",
      "   # Treinar um modelo espec√≠fico\n",
      "   resultado = treinar_xgboost_componente('d1', 1)\n",
      "\n",
      "   # Treinar todos os modelos\n",
      "   resultados = treinar_todos_componentes([1, 5, 7, 30])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def criar_dataset_simples(series, look_back=5, passo=1):\n",
    "    \"\"\"\n",
    "    Criar dataset SIMPLES - apenas sequ√™ncia temporal (igual ao LSTM)\n",
    "    SEM features engineering\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - look_back - passo + 1):\n",
    "        # Apenas a sequ√™ncia temporal\n",
    "        sequencia = series[i:i + look_back]\n",
    "        target = series[i + look_back + passo - 1]\n",
    "        \n",
    "        X.append(sequencia.flatten())\n",
    "        y.append(target[0])  # target √© array, pegar valor\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def treinar_xgboost_componente(nome_comp, passo=1, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Treinar modelo XGBoost para um componente espec√≠fico\n",
    "    Usando APENAS sequ√™ncias temporais (sem features engineering)\n",
    "    \"\"\"\n",
    "    print(f\"üå≤ TREINANDO XGBOOST SIMPLES - {nome_comp.upper()} para t+{passo}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Carregar dados\n",
    "    print(f\"üìä 1. Carregando dados {nome_comp.upper()}...\")\n",
    "    comp_file = f\"{nome_comp.upper()}_component.csv\"\n",
    "    if not Path(comp_file).exists():\n",
    "        raise FileNotFoundError(f\"Arquivo n√£o encontrado: {comp_file}\")\n",
    "    \n",
    "    df = pd.read_csv(comp_file)\n",
    "    if nome_comp.upper() not in df.columns:\n",
    "        raise ValueError(f\"Coluna {nome_comp.upper()} n√£o encontrada em {comp_file}\")\n",
    "    \n",
    "    data = df[nome_comp.upper()].values.reshape(-1, 1)\n",
    "    print(f\"   ‚úÖ Dados carregados: {len(data)} pontos\")\n",
    "    print(f\"   üìà Range: [{data.min():.4f}, {data.max():.4f}]\")\n",
    "    print(f\"   üìä Std: {np.std(data):.4f}\")\n",
    "    \n",
    "    # 2. Normaliza√ß√£o\n",
    "    print(f\"\\nüîß 2. Aplicando normaliza√ß√£o...\")\n",
    "    scaler = RobustScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    print(f\"   ‚úÖ Scaler: RobustScaler\")\n",
    "    print(f\"   üìà Range normalizado: [{data_scaled.min():.4f}, {data_scaled.max():.4f}]\")\n",
    "    \n",
    "    # 3. Criar dataset\n",
    "    print(f\"\\nüì¶ 3. Criando dataset...\")\n",
    "    look_back = 5 if passo in [1, 5] else 10  # Regra original\n",
    "    print(f\"   üìè Look_back: {look_back}\")\n",
    "    print(f\"   üéØ Passo de previs√£o: {passo}\")\n",
    "    \n",
    "    X, y = criar_dataset_simples(data_scaled, look_back, passo)\n",
    "    print(f\"   ‚úÖ Dataset criado:\")\n",
    "    print(f\"      X shape: {X.shape} (apenas sequ√™ncias temporais)\")\n",
    "    print(f\"      y shape: {y.shape}\")\n",
    "    print(f\"      Features: {X.shape[1]} (= look_back, SEM features engineering)\")\n",
    "    \n",
    "    # 4. Divis√£o treino/teste\n",
    "    print(f\"\\n‚úÇÔ∏è 4. Dividindo dados...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, shuffle=False\n",
    "    )\n",
    "    print(f\"   ‚úÖ Treino: {X_train.shape[0]} amostras\")\n",
    "    print(f\"   ‚úÖ Teste: {X_test.shape[0]} amostras\")\n",
    "    \n",
    "    # 5. Configurar XGBoost\n",
    "    print(f\"\\nü§ñ 5. Configurando XGBoost...\")\n",
    "    xgb_params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 100,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'random_state': random_state,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    print(f\"   üìã Par√¢metros:\")\n",
    "    for param, valor in xgb_params.items():\n",
    "        print(f\"      {param}: {valor}\")\n",
    "    \n",
    "    # 6. Treinar modelo\n",
    "    print(f\"\\nüöÄ 6. Treinando modelo...\")\n",
    "    modelo = xgb.XGBRegressor(**xgb_params)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    print(f\"   ‚úÖ Treinamento conclu√≠do!\")\n",
    "    \n",
    "    # 7. Avaliar modelo\n",
    "    print(f\"\\nüìä 7. Avaliando performance...\")\n",
    "    \n",
    "    # Previs√µes\n",
    "    y_pred_train = modelo.predict(X_train)\n",
    "    y_pred_test = modelo.predict(X_test)\n",
    "    \n",
    "    # Desnormalizar para m√©tricas\n",
    "    y_train_real = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "    y_test_real = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "    y_pred_train_real = scaler.inverse_transform(y_pred_train.reshape(-1, 1)).flatten()\n",
    "    y_pred_test_real = scaler.inverse_transform(y_pred_test.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # M√©tricas treino\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train_real, y_pred_train_real))\n",
    "    mae_train = mean_absolute_error(y_train_real, y_pred_train_real)\n",
    "    \n",
    "    # M√©tricas teste\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test_real, y_pred_test_real))\n",
    "    mae_test = mean_absolute_error(y_test_real, y_pred_test_real)\n",
    "    \n",
    "    print(f\"   üìà TREINO:\")\n",
    "    print(f\"      RMSE: {rmse_train:.4f}\")\n",
    "    print(f\"      MAE:  {mae_train:.4f}\")\n",
    "    print(f\"   üìà TESTE:\")\n",
    "    print(f\"      RMSE: {rmse_test:.4f}\")\n",
    "    print(f\"      MAE:  {mae_test:.4f}\")\n",
    "    \n",
    "    # Verificar overfitting\n",
    "    overfitting_ratio = rmse_test / rmse_train\n",
    "    if overfitting_ratio > 1.5:\n",
    "        print(f\"   ‚ö†Ô∏è Poss√≠vel overfitting (ratio: {overfitting_ratio:.2f})\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Sem overfitting (ratio: {overfitting_ratio:.2f})\")\n",
    "    \n",
    "    # 8. Salvar arquivos\n",
    "    print(f\"\\nüíæ 8. Salvando arquivos...\")\n",
    "    \n",
    "    # Criar diret√≥rios\n",
    "    os.makedirs(\"modelosXGB\", exist_ok=True)\n",
    "    os.makedirs(\"scalersXGB\", exist_ok=True)\n",
    "    os.makedirs(\"configsXGB\", exist_ok=True)\n",
    "    \n",
    "    # Salvar modelo\n",
    "    modelo_path = f\"modelosXGB/xgb_{nome_comp.lower()}_t{passo}.joblib\"\n",
    "    joblib.dump(modelo, modelo_path)\n",
    "    print(f\"   ‚úÖ Modelo salvo: {modelo_path}\")\n",
    "    \n",
    "    # Salvar scaler\n",
    "    scaler_path = f\"scalersXGB/scaler_{nome_comp.lower()}_t{passo}.joblib\"\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f\"   ‚úÖ Scaler salvo: {scaler_path}\")\n",
    "    \n",
    "    # Salvar configura√ß√£o\n",
    "    config = {\n",
    "        'componente': nome_comp.upper(),\n",
    "        'passo': passo,\n",
    "        'look_back': look_back,\n",
    "        'n_features_total': X.shape[1],\n",
    "        'n_features_sequencia': look_back,\n",
    "        'n_features_engineering': 0,  # SEM features engineering\n",
    "        'scaler_type': 'RobustScaler',\n",
    "        'model_type': 'XGBRegressor',\n",
    "        'xgb_params': xgb_params,\n",
    "        'dataset_info': {\n",
    "            'total_samples': len(X),\n",
    "            'train_samples': len(X_train),\n",
    "            'test_samples': len(X_test),\n",
    "            'data_range_original': [float(data.min()), float(data.max())],\n",
    "            'data_range_scaled': [float(data_scaled.min()), float(data_scaled.max())]\n",
    "        },\n",
    "        'performance': {\n",
    "            'rmse_train': float(rmse_train),\n",
    "            'mae_train': float(mae_train),\n",
    "            'rmse_test': float(rmse_test),\n",
    "            'mae_test': float(mae_test),\n",
    "            'overfitting_ratio': float(overfitting_ratio)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config_path = f\"configsXGB/config_{nome_comp.lower()}_t{passo}.json\"\n",
    "    with open(config_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"   ‚úÖ Config salva: {config_path}\")\n",
    "    \n",
    "    # 9. Teste de sanidade\n",
    "    print(f\"\\nüß™ 9. Teste de sanidade...\")\n",
    "    \n",
    "    # Carregar modelo salvo e testar\n",
    "    modelo_carregado = joblib.load(modelo_path)\n",
    "    scaler_carregado = joblib.load(scaler_path)\n",
    "    \n",
    "    # Teste com uma amostra\n",
    "    amostra_teste = X_test[:5]  # 5 amostras\n",
    "    pred_teste = modelo_carregado.predict(amostra_teste)\n",
    "    pred_teste_real = scaler_carregado.inverse_transform(pred_teste.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    print(f\"   ‚úÖ Modelo carregado e testado:\")\n",
    "    print(f\"      Amostras teste: {len(amostra_teste)}\")\n",
    "    print(f\"      Previs√µes (normalizado): {pred_teste[:3]}\")\n",
    "    print(f\"      Previs√µes (real): {pred_teste_real[:3]}\")\n",
    "    print(f\"      Variabilidade: {np.std(pred_teste_real):.4f}\")\n",
    "    \n",
    "    print(f\"\\nüéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\")\n",
    "    print(f\"   üìÅ Arquivos salvos:\")\n",
    "    print(f\"      - {modelo_path}\")\n",
    "    print(f\"      - {scaler_path}\")\n",
    "    print(f\"      - {config_path}\")\n",
    "    \n",
    "    return {\n",
    "        'modelo': modelo,\n",
    "        'scaler': scaler,\n",
    "        'config': config,\n",
    "        'performance': {\n",
    "            'rmse_test': rmse_test,\n",
    "            'mae_test': mae_test,\n",
    "            'overfitting_ratio': overfitting_ratio\n",
    "        }\n",
    "    }\n",
    "\n",
    "def treinar_todos_componentes(passos=[1, 5, 7, 30]):\n",
    "    \"\"\"\n",
    "    Treinar modelos XGBoost para todos os componentes D1, D2, D3\n",
    "    em todos os horizontes de previs√£o\n",
    "    \"\"\"\n",
    "    print(\"üöÄ TREINAMENTO COMPLETO - XGBOOST SIMPLES\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"üìã Componentes: D1, D2, D3\")\n",
    "    print(f\"üéØ Horizontes: {passos}\")\n",
    "    print(f\"üîß Abordagem: Apenas sequ√™ncias temporais (sem features)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    resultados = {}\n",
    "    componentes = ['d1', 'd2', 'd3']\n",
    "    \n",
    "    total_modelos = len(componentes) * len(passos)\n",
    "    contador = 0\n",
    "    \n",
    "    for comp in componentes:\n",
    "        resultados[comp] = {}\n",
    "        \n",
    "        for passo in passos:\n",
    "            contador += 1\n",
    "            print(f\"\\n{'üü¢' * contador}{'‚ö™' * (total_modelos - contador)} PROGRESSO: {contador}/{total_modelos}\")\n",
    "            print(f\"üéØ Treinando {comp.upper()} para t+{passo}\")\n",
    "            \n",
    "            try:\n",
    "                resultado = treinar_xgboost_componente(comp, passo)\n",
    "                resultados[comp][f't+{passo}'] = resultado['performance']\n",
    "                print(f\"‚úÖ {comp.upper()} t+{passo} - SUCESSO (RMSE: {resultado['performance']['rmse_test']:.4f})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå {comp.upper()} t+{passo} - ERRO: {e}\")\n",
    "                resultados[comp][f't+{passo}'] = {'erro': str(e)}\n",
    "    \n",
    "    # Resumo final\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(\"üìä RESUMO FINAL DO TREINAMENTO\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"{'Componente':<12} {'Horizonte':<10} {'RMSE':<8} {'MAE':<8} {'Status':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    sucessos = 0\n",
    "    falhas = 0\n",
    "    \n",
    "    for comp in componentes:\n",
    "        for passo in passos:\n",
    "            key = f't+{passo}'\n",
    "            if key in resultados[comp]:\n",
    "                if 'erro' in resultados[comp][key]:\n",
    "                    print(f\"{comp.upper():<12} {key:<10} {'N/A':<8} {'N/A':<8} {'ERRO':<10}\")\n",
    "                    falhas += 1\n",
    "                else:\n",
    "                    perf = resultados[comp][key]\n",
    "                    rmse = perf['rmse_test']\n",
    "                    mae = perf['mae_test']\n",
    "                    print(f\"{comp.upper():<12} {key:<10} {rmse:<8.4f} {mae:<8.4f} {'OK':<10}\")\n",
    "                    sucessos += 1\n",
    "    \n",
    "    print(f\"\\nüìä ESTAT√çSTICAS:\")\n",
    "    print(f\"   ‚úÖ Sucessos: {sucessos}\")\n",
    "    print(f\"   ‚ùå Falhas: {falhas}\")\n",
    "    print(f\"   üìà Taxa de sucesso: {(sucessos/(sucessos+falhas)*100):.1f}%\")\n",
    "    \n",
    "    # Salvar resumo\n",
    "    resumo_path = \"configsXGB/resumo_treinamento.json\"\n",
    "    resumo = {\n",
    "        'data_treinamento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'abordagem': 'XGBoost simples - apenas sequ√™ncias temporais',\n",
    "        'componentes': componentes,\n",
    "        'horizontes': passos,\n",
    "        'total_modelos': total_modelos,\n",
    "        'sucessos': sucessos,\n",
    "        'falhas': falhas,\n",
    "        'resultados': resultados\n",
    "    }\n",
    "    \n",
    "    with open(resumo_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(resumo, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Resumo salvo: {resumo_path}\")\n",
    "    \n",
    "    if sucessos == total_modelos:\n",
    "        print(f\"\\nüéâ TODOS OS MODELOS TREINADOS COM SUCESSO!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Alguns modelos falharam. Verifique os logs acima.\")\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Interface de uso\n",
    "print(\"üå≤ TREINAMENTO XGBOOST SIMPLES\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üìã Fun√ß√µes dispon√≠veis:\")\n",
    "print()\n",
    "print(\"üîπ treinar_xgboost_componente('d1', passo=1)\")\n",
    "print(\"   ‚Üí Treina um modelo espec√≠fico\")\n",
    "print()\n",
    "print(\"üîπ treinar_todos_componentes([1, 5, 7, 30])\")\n",
    "print(\"   ‚Üí Treina todos os modelos para todos os horizontes\")\n",
    "print()\n",
    "print(\"üí° CARACTER√çSTICAS DOS MODELOS:\")\n",
    "print(\"   ‚Ä¢ Apenas sequ√™ncias temporais (sem features)\")\n",
    "print(\"   ‚Ä¢ Look_back: 5 para t+1,t+5 | 10 para demais\")\n",
    "print(\"   ‚Ä¢ Scaler: RobustScaler\")\n",
    "print(\"   ‚Ä¢ Modelo: XGBRegressor\")\n",
    "print(\"   ‚Ä¢ Consistente com LSTM (apenas sequ√™ncias)\")\n",
    "print()\n",
    "print(\"üéØ EXEMPLO DE USO:\")\n",
    "print(\"   # Treinar um modelo espec√≠fico\")\n",
    "print(\"   resultado = treinar_xgboost_componente('d1', 1)\")\n",
    "print()\n",
    "print(\"   # Treinar todos os modelos\")\n",
    "print(\"   resultados = treinar_todos_componentes([1, 5, 7, 30])\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efec5419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ TREINAMENTO COMPLETO - XGBOOST SIMPLES\n",
      "======================================================================\n",
      "üìã Componentes: D1, D2, D3\n",
      "üéØ Horizontes: [1, 5, 7, 30]\n",
      "üîß Abordagem: Apenas sequ√™ncias temporais (sem features)\n",
      "======================================================================\n",
      "\n",
      "üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 1/12\n",
      "üéØ Treinando D1 para t+1\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D1 para t+1\n",
      "============================================================\n",
      "üìä 1. Carregando dados D1...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-7.7183, 8.8608]\n",
      "   üìä Std: 1.3112\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.4508, 6.2790]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 1\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7873, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7873,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6298 amostras\n",
      "   ‚úÖ Teste: 1575 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.4349\n",
      "      MAE:  0.3211\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.6484\n",
      "      MAE:  0.4056\n",
      "   ‚úÖ Sem overfitting (ratio: 1.49)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d1_t1.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d1_t1.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d1_t1.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [ 0.584285   -0.45116338  0.69318074]\n",
      "      Previs√µes (real): [ 0.81178224 -0.6517462   0.9656982 ]\n",
      "      Variabilidade: 1.1464\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d1_t1.joblib\n",
      "      - scalersXGB/scaler_d1_t1.joblib\n",
      "      - configsXGB/config_d1_t1.json\n",
      "‚úÖ D1 t+1 - SUCESSO (RMSE: 0.6484)\n",
      "\n",
      "üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 2/12\n",
      "üéØ Treinando D1 para t+5\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D1 para t+5\n",
      "============================================================\n",
      "üìä 1. Carregando dados D1...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-7.7183, 8.8608]\n",
      "   üìä Std: 1.3112\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.4508, 6.2790]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 5\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7869, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7869,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6295 amostras\n",
      "   ‚úÖ Teste: 1574 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 1.0611\n",
      "      MAE:  0.7942\n",
      "   üìà TESTE:\n",
      "      RMSE: 1.2844\n",
      "      MAE:  0.8899\n",
      "   ‚úÖ Sem overfitting (ratio: 1.21)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d1_t5.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d1_t5.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d1_t5.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.0651862  -0.04699963  0.33018985]\n",
      "      Previs√µes (real): [-0.10619649 -0.08049113  0.45263782]\n",
      "      Variabilidade: 0.2410\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d1_t5.joblib\n",
      "      - scalersXGB/scaler_d1_t5.joblib\n",
      "      - configsXGB/config_d1_t5.json\n",
      "‚úÖ D1 t+5 - SUCESSO (RMSE: 1.2844)\n",
      "\n",
      "üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 3/12\n",
      "üéØ Treinando D1 para t+7\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D1 para t+7\n",
      "============================================================\n",
      "üìä 1. Carregando dados D1...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-7.7183, 8.8608]\n",
      "   üìä Std: 1.3112\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.4508, 6.2790]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 7\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7862, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7862,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6289 amostras\n",
      "   ‚úÖ Teste: 1573 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.9921\n",
      "      MAE:  0.7364\n",
      "   üìà TESTE:\n",
      "      RMSE: 1.2963\n",
      "      MAE:  0.8930\n",
      "   ‚úÖ Sem overfitting (ratio: 1.31)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d1_t7.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d1_t7.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d1_t7.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [ 0.05505536  0.0490999  -0.10294696]\n",
      "      Previs√µes (real): [ 0.06375592  0.05533831 -0.15956849]\n",
      "      Variabilidade: 0.1094\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d1_t7.joblib\n",
      "      - scalersXGB/scaler_d1_t7.joblib\n",
      "      - configsXGB/config_d1_t7.json\n",
      "‚úÖ D1 t+7 - SUCESSO (RMSE: 1.2963)\n",
      "\n",
      "üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 4/12\n",
      "üéØ Treinando D1 para t+30\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D1 para t+30\n",
      "============================================================\n",
      "üìä 1. Carregando dados D1...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-7.7183, 8.8608]\n",
      "   üìä Std: 1.3112\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.4508, 6.2790]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 30\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7839, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7839,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6271 amostras\n",
      "   ‚úÖ Teste: 1568 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.9840\n",
      "      MAE:  0.7355\n",
      "   üìà TESTE:\n",
      "      RMSE: 1.2662\n",
      "      MAE:  0.8643\n",
      "   ‚úÖ Sem overfitting (ratio: 1.29)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d1_t30.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d1_t30.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d1_t30.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.35312077  0.27458915 -0.06779321]\n",
      "      Previs√µes (real): [-0.51317036  0.3740504  -0.1098813 ]\n",
      "      Variabilidade: 0.2915\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d1_t30.joblib\n",
      "      - scalersXGB/scaler_d1_t30.joblib\n",
      "      - configsXGB/config_d1_t30.json\n",
      "‚úÖ D1 t+30 - SUCESSO (RMSE: 1.2662)\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 5/12\n",
      "üéØ Treinando D2 para t+1\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D2 para t+1\n",
      "============================================================\n",
      "üìä 1. Carregando dados D2...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-6.5773, 6.5198]\n",
      "   üìä Std: 1.0992\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.2595, 5.2220]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 1\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7873, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7873,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6298 amostras\n",
      "   ‚úÖ Teste: 1575 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.2462\n",
      "      MAE:  0.1781\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.3030\n",
      "      MAE:  0.2054\n",
      "   ‚úÖ Sem overfitting (ratio: 1.23)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d2_t1.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d2_t1.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d2_t1.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [ 0.40283275  0.19148317 -0.48707783]\n",
      "      Previs√µes (real): [ 0.49794427  0.23385319 -0.6140402 ]\n",
      "      Variabilidade: 0.6553\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d2_t1.joblib\n",
      "      - scalersXGB/scaler_d2_t1.joblib\n",
      "      - configsXGB/config_d2_t1.json\n",
      "‚úÖ D2 t+1 - SUCESSO (RMSE: 0.3030)\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 6/12\n",
      "üéØ Treinando D2 para t+5\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D2 para t+5\n",
      "============================================================\n",
      "üìä 1. Carregando dados D2...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-6.5773, 6.5198]\n",
      "   üìä Std: 1.0992\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.2595, 5.2220]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 5\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7869, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7869,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6295 amostras\n",
      "   ‚úÖ Teste: 1574 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.7905\n",
      "      MAE:  0.6014\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.8701\n",
      "      MAE:  0.6254\n",
      "   ‚úÖ Sem overfitting (ratio: 1.10)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d2_t5.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d2_t5.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d2_t5.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [ 0.30461815 -0.07328987 -0.17492181]\n",
      "      Previs√µes (real): [ 0.37522057 -0.09699299 -0.2239868 ]\n",
      "      Variabilidade: 0.2078\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d2_t5.joblib\n",
      "      - scalersXGB/scaler_d2_t5.joblib\n",
      "      - configsXGB/config_d2_t5.json\n",
      "‚úÖ D2 t+5 - SUCESSO (RMSE: 0.8701)\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 7/12\n",
      "üéØ Treinando D2 para t+7\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D2 para t+7\n",
      "============================================================\n",
      "üìä 1. Carregando dados D2...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-6.5773, 6.5198]\n",
      "   üìä Std: 1.0992\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.2595, 5.2220]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 7\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7862, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7862,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6289 amostras\n",
      "   ‚úÖ Teste: 1573 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.8227\n",
      "      MAE:  0.6231\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.9436\n",
      "      MAE:  0.6870\n",
      "   ‚úÖ Sem overfitting (ratio: 1.15)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d2_t7.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d2_t7.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d2_t7.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.15706782  0.02677786 -0.19647865]\n",
      "      Previs√µes (real): [-0.20167743  0.02804627 -0.2509231 ]\n",
      "      Variabilidade: 0.1337\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d2_t7.joblib\n",
      "      - scalersXGB/scaler_d2_t7.joblib\n",
      "      - configsXGB/config_d2_t7.json\n",
      "‚úÖ D2 t+7 - SUCESSO (RMSE: 0.9436)\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 8/12\n",
      "üéØ Treinando D2 para t+30\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D2 para t+30\n",
      "============================================================\n",
      "üìä 1. Carregando dados D2...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-6.5773, 6.5198]\n",
      "   üìä Std: 1.0992\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.2595, 5.2220]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 30\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7839, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7839,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6271 amostras\n",
      "   ‚úÖ Teste: 1568 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.8623\n",
      "      MAE:  0.6512\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.9557\n",
      "      MAE:  0.6936\n",
      "   ‚úÖ Sem overfitting (ratio: 1.11)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d2_t30.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d2_t30.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d2_t30.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.08274496 -0.11594367 -0.20993264]\n",
      "      Previs√µes (real): [-0.10880757 -0.15029089 -0.26773447]\n",
      "      Variabilidade: 0.2015\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d2_t30.joblib\n",
      "      - scalersXGB/scaler_d2_t30.joblib\n",
      "      - configsXGB/config_d2_t30.json\n",
      "‚úÖ D2 t+30 - SUCESSO (RMSE: 0.9557)\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™ PROGRESSO: 9/12\n",
      "üéØ Treinando D3 para t+1\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D3 para t+1\n",
      "============================================================\n",
      "üìä 1. Carregando dados D3...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-5.7485, 5.2615]\n",
      "   üìä Std: 1.0421\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.1403, 4.6939]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 1\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7873, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7873,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6298 amostras\n",
      "   ‚úÖ Teste: 1575 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.1643\n",
      "      MAE:  0.1240\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.1899\n",
      "      MAE:  0.1391\n",
      "   ‚úÖ Sem overfitting (ratio: 1.16)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d3_t1.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d3_t1.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d3_t1.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.75686723 -0.41488513 -0.7490523 ]\n",
      "      Previs√µes (real): [-0.84094405 -0.45807716 -0.8321948 ]\n",
      "      Variabilidade: 0.1595\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d3_t1.joblib\n",
      "      - scalersXGB/scaler_d3_t1.joblib\n",
      "      - configsXGB/config_d3_t1.json\n",
      "‚úÖ D3 t+1 - SUCESSO (RMSE: 0.1899)\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™ PROGRESSO: 10/12\n",
      "üéØ Treinando D3 para t+5\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D3 para t+5\n",
      "============================================================\n",
      "üìä 1. Carregando dados D3...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-5.7485, 5.2615]\n",
      "   üìä Std: 1.0421\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.1403, 4.6939]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 5\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7869, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7869,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6295 amostras\n",
      "   ‚úÖ Teste: 1574 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.4775\n",
      "      MAE:  0.3543\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.4905\n",
      "      MAE:  0.3455\n",
      "   ‚úÖ Sem overfitting (ratio: 1.03)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d3_t5.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d3_t5.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d3_t5.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.7152981  -0.81282276 -1.2286726 ]\n",
      "      Previs√µes (real): [-0.7944052 -0.9035892 -1.3691549]\n",
      "      Variabilidade: 0.2638\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d3_t5.joblib\n",
      "      - scalersXGB/scaler_d3_t5.joblib\n",
      "      - configsXGB/config_d3_t5.json\n",
      "‚úÖ D3 t+5 - SUCESSO (RMSE: 0.4905)\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™ PROGRESSO: 11/12\n",
      "üéØ Treinando D3 para t+7\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D3 para t+7\n",
      "============================================================\n",
      "üìä 1. Carregando dados D3...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-5.7485, 5.2615]\n",
      "   üìä Std: 1.0421\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.1403, 4.6939]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 7\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7862, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7862,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6289 amostras\n",
      "   ‚úÖ Teste: 1573 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.5429\n",
      "      MAE:  0.4012\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.6433\n",
      "      MAE:  0.4451\n",
      "   ‚úÖ Sem overfitting (ratio: 1.19)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d3_t7.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d3_t7.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d3_t7.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.5504107  -0.23613088 -0.7539233 ]\n",
      "      Previs√µes (real): [-0.6098051  -0.2579524  -0.83764815]\n",
      "      Variabilidade: 0.2139\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d3_t7.joblib\n",
      "      - scalersXGB/scaler_d3_t7.joblib\n",
      "      - configsXGB/config_d3_t7.json\n",
      "‚úÖ D3 t+7 - SUCESSO (RMSE: 0.6433)\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢ PROGRESSO: 12/12\n",
      "üéØ Treinando D3 para t+30\n",
      "üå≤ TREINANDO XGBOOST SIMPLES - D3 para t+30\n",
      "============================================================\n",
      "üìä 1. Carregando dados D3...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-5.7485, 5.2615]\n",
      "   üìä Std: 1.0421\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.1403, 4.6939]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 30\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7839, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7839,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6271 amostras\n",
      "   ‚úÖ Teste: 1568 amostras\n",
      "\n",
      "ü§ñ 5. Configurando XGBoost...\n",
      "   üìã Par√¢metros:\n",
      "      objective: reg:squarederror\n",
      "      max_depth: 6\n",
      "      learning_rate: 0.1\n",
      "      n_estimators: 100\n",
      "      subsample: 0.8\n",
      "      colsample_bytree: 0.8\n",
      "      random_state: 42\n",
      "      n_jobs: -1\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do!\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.8282\n",
      "      MAE:  0.6280\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.8431\n",
      "      MAE:  0.6081\n",
      "   ‚úÖ Sem overfitting (ratio: 1.02)\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosXGB/xgb_d3_t30.joblib\n",
      "   ‚úÖ Scaler salvo: scalersXGB/scaler_d3_t30.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d3_t30.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [0.41620904 0.12506406 0.14407583]\n",
      "      Previs√µes (real): [0.47237644 0.14642434 0.16770901]\n",
      "      Variabilidade: 0.2389\n",
      "\n",
      "üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosXGB/xgb_d3_t30.joblib\n",
      "      - scalersXGB/scaler_d3_t30.joblib\n",
      "      - configsXGB/config_d3_t30.json\n",
      "‚úÖ D3 t+30 - SUCESSO (RMSE: 0.8431)\n",
      "\n",
      "======================================================================\n",
      "üìä RESUMO FINAL DO TREINAMENTO\n",
      "======================================================================\n",
      "Componente   Horizonte  RMSE     MAE      Status    \n",
      "------------------------------------------------------------\n",
      "D1           t+1        0.6484   0.4056   OK        \n",
      "D1           t+5        1.2844   0.8899   OK        \n",
      "D1           t+7        1.2963   0.8930   OK        \n",
      "D1           t+30       1.2662   0.8643   OK        \n",
      "D2           t+1        0.3030   0.2054   OK        \n",
      "D2           t+5        0.8701   0.6254   OK        \n",
      "D2           t+7        0.9436   0.6870   OK        \n",
      "D2           t+30       0.9557   0.6936   OK        \n",
      "D3           t+1        0.1899   0.1391   OK        \n",
      "D3           t+5        0.4905   0.3455   OK        \n",
      "D3           t+7        0.6433   0.4451   OK        \n",
      "D3           t+30       0.8431   0.6081   OK        \n",
      "\n",
      "üìä ESTAT√çSTICAS:\n",
      "   ‚úÖ Sucessos: 12\n",
      "   ‚ùå Falhas: 0\n",
      "   üìà Taxa de sucesso: 100.0%\n",
      "\n",
      "üíæ Resumo salvo: configsXGB/resumo_treinamento.json\n",
      "\n",
      "üéâ TODOS OS MODELOS TREINADOS COM SUCESSO!\n"
     ]
    }
   ],
   "source": [
    "# Treinar todos os componentes D1, D2, D3 para todos os horizontes\n",
    "resultados = treinar_todos_componentes([1, 5, 7, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84a8d1",
   "metadata": {},
   "source": [
    "## Vars√£o para mellhoara os picos e Depress√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff74ff27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ ENSEMBLE ESPECIALIZADO - IMPLEMENTA√á√ÉO PR√ÅTICA\n",
      "============================================================\n",
      "üìã FUN√á√ïES DISPON√çVEIS:\n",
      "\n",
      "üîπ treinar_ensemble_especializado_componente('d1', passo=1)\n",
      "   ‚Üí Treina ensemble para um componente espec√≠fico\n",
      "\n",
      "üîπ treinar_todos_ensembles([1, 5, 7, 30])\n",
      "   ‚Üí Treina ensembles para todos os componentes\n",
      "\n",
      "üí° COMO USAR:\n",
      "   1. Execute: treinar_todos_ensembles([1, 5, 7, 30])\n",
      "   2. Aguarde o treinamento (5-15 minutos)\n",
      "   3. Use o c√≥digo de avalia√ß√£o normalmente\n",
      "\n",
      "üéØ DIFEREN√áA:\n",
      "   ‚Ä¢ 3 modelos por componente (baixos/m√©dios/altos)\n",
      "   ‚Ä¢ Foco espec√≠fico em picos e depress√µes\n",
      "   ‚Ä¢ Combina√ß√£o inteligente das previs√µes\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# ENSEMBLE ESPECIALIZADO - IMPLEMENTA√á√ÉO PR√ÅTICA\n",
    "# ====================================================================\n",
    "# Este c√≥digo SUBSTITUI o treinamento XGBoost normal\n",
    "# Treina 3 modelos por componente: baixos, m√©dios, altos\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def criar_dataset_simples(series, look_back=5, passo=1):\n",
    "    \"\"\"Dataset simples - apenas sequ√™ncias\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - look_back - passo + 1):\n",
    "        sequencia = series[i:i + look_back]\n",
    "        target = series[i + look_back + passo - 1]\n",
    "        X.append(sequencia.flatten())\n",
    "        y.append(target[0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def treinar_ensemble_especializado_componente(nome_comp, passo=1, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Treina ensemble especializado para um componente\n",
    "    3 modelos: baixos, m√©dios, altos + 1 modelo geral\n",
    "    \"\"\"\n",
    "    print(f\"üéØ ENSEMBLE ESPECIALIZADO - {nome_comp.upper()} t+{passo}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Carregar dados\n",
    "    comp_file = f\"{nome_comp.upper()}_component.csv\"\n",
    "    if not Path(comp_file).exists():\n",
    "        raise FileNotFoundError(f\"Arquivo n√£o encontrado: {comp_file}\")\n",
    "    \n",
    "    df = pd.read_csv(comp_file)\n",
    "    data = df[nome_comp.upper()].values.reshape(-1, 1)\n",
    "    \n",
    "    print(f\"üìä Dados carregados: {len(data)} pontos\")\n",
    "    print(f\"   Range: [{data.min():.4f}, {data.max():.4f}]\")\n",
    "    \n",
    "    # 2. Normaliza√ß√£o\n",
    "    scaler = RobustScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "    # 3. Criar dataset\n",
    "    look_back = 5 if passo in [1, 5] else 10\n",
    "    X, y = criar_dataset_simples(data_scaled, look_back, passo)\n",
    "    \n",
    "    print(f\"üì¶ Dataset: {X.shape}, look_back={look_back}\")\n",
    "    \n",
    "    # 4. Divis√£o treino/teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, shuffle=False\n",
    "    )\n",
    "    \n",
    "    # 5. IDENTIFICAR REGI√ïES (percentis na escala original)\n",
    "    y_train_original = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    p25, p50, p75 = np.percentile(y_train_original, [25, 50, 75])\n",
    "    print(f\"üéØ Percentis: P25={p25:.3f}, P50={p50:.3f}, P75={p75:.3f}\")\n",
    "    \n",
    "    # M√°scaras para especialistas\n",
    "    baixos_mask = y_train_original <= p25\n",
    "    medios_mask = (y_train_original > p25) & (y_train_original < p75)\n",
    "    altos_mask = y_train_original >= p75\n",
    "    \n",
    "    print(f\"üìä Distribui√ß√£o:\")\n",
    "    print(f\"   Baixos: {np.sum(baixos_mask)} amostras ({np.sum(baixos_mask)/len(y_train)*100:.1f}%)\")\n",
    "    print(f\"   M√©dios: {np.sum(medios_mask)} amostras ({np.sum(medios_mask)/len(y_train)*100:.1f}%)\")\n",
    "    print(f\"   Altos:  {np.sum(altos_mask)} amostras ({np.sum(altos_mask)/len(y_train)*100:.1f}%)\")\n",
    "    \n",
    "    # 6. TREINAR MODELOS ESPECIALISTAS\n",
    "    modelos = {}\n",
    "    \n",
    "    # Par√¢metros base\n",
    "    base_params = {\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    # Modelo para BAIXOS (foco em depress√µes)\n",
    "    if np.sum(baixos_mask) >= 20:  # M√≠nimo de amostras\n",
    "        print(f\"\\nüîΩ Treinando especialista BAIXOS...\")\n",
    "        modelo_baixos = xgb.XGBRegressor(\n",
    "            max_depth=8,  # Mais profundo para capturar padr√µes raros\n",
    "            learning_rate=0.05,  # Mais conservador\n",
    "            n_estimators=300,  # Mais √°rvores\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            objective='reg:absoluteerror',  # MAE para extremos\n",
    "            **base_params\n",
    "        )\n",
    "        \n",
    "        modelo_baixos.fit(X_train[baixos_mask], y_train[baixos_mask])\n",
    "        \n",
    "        # Avaliar\n",
    "        if np.sum(baixos_mask) > 0:\n",
    "            pred_baixos_train = modelo_baixos.predict(X_train[baixos_mask])\n",
    "            rmse_baixos = np.sqrt(mean_squared_error(y_train[baixos_mask], pred_baixos_train))\n",
    "            print(f\"      RMSE treino: {rmse_baixos:.4f}\")\n",
    "        \n",
    "        modelos['baixos'] = modelo_baixos\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Poucos dados para especialista BAIXOS ({np.sum(baixos_mask)} amostras)\")\n",
    "        modelos['baixos'] = None\n",
    "    \n",
    "    # Modelo para ALTOS (foco em picos)\n",
    "    if np.sum(altos_mask) >= 20:\n",
    "        print(f\"\\nüîº Treinando especialista ALTOS...\")\n",
    "        modelo_altos = xgb.XGBRegressor(\n",
    "            max_depth=8,\n",
    "            learning_rate=0.05,\n",
    "            n_estimators=300,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            objective='reg:absoluteerror',\n",
    "            **base_params\n",
    "        )\n",
    "        \n",
    "        modelo_altos.fit(X_train[altos_mask], y_train[altos_mask])\n",
    "        \n",
    "        if np.sum(altos_mask) > 0:\n",
    "            pred_altos_train = modelo_altos.predict(X_train[altos_mask])\n",
    "            rmse_altos = np.sqrt(mean_squared_error(y_train[altos_mask], pred_altos_train))\n",
    "            print(f\"      RMSE treino: {rmse_altos:.4f}\")\n",
    "        \n",
    "        modelos['altos'] = modelo_altos\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Poucos dados para especialista ALTOS ({np.sum(altos_mask)} amostras)\")\n",
    "        modelos['altos'] = None\n",
    "    \n",
    "    # Modelo GERAL (baseline)\n",
    "    print(f\"\\n‚öñÔ∏è Treinando modelo GERAL...\")\n",
    "    modelo_geral = xgb.XGBRegressor(\n",
    "        max_depth=6,  # Padr√£o\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=200,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='reg:squarederror',  # RMSE padr√£o\n",
    "        **base_params\n",
    "    )\n",
    "    \n",
    "    modelo_geral.fit(X_train, y_train)\n",
    "    modelos['geral'] = modelo_geral\n",
    "    \n",
    "    # 7. PREVIS√ÉO ENSEMBLE NO TESTE\n",
    "    print(f\"\\nüîÄ Fazendo previs√£o ensemble...\")\n",
    "    \n",
    "    pred_geral = modelo_geral.predict(X_test)\n",
    "    pred_geral_original = scaler.inverse_transform(pred_geral.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Identificar regi√µes no teste baseado na previs√£o geral\n",
    "    p25_test, p75_test = np.percentile(pred_geral_original, [25, 75])\n",
    "    \n",
    "    baixos_test_mask = pred_geral_original <= p25_test\n",
    "    altos_test_mask = pred_geral_original >= p75_test\n",
    "    medios_test_mask = ~(baixos_test_mask | altos_test_mask)\n",
    "    \n",
    "    print(f\"üìä Distribui√ß√£o no teste:\")\n",
    "    print(f\"   Baixos: {np.sum(baixos_test_mask)} ({np.sum(baixos_test_mask)/len(pred_geral)*100:.1f}%)\")\n",
    "    print(f\"   M√©dios: {np.sum(medios_test_mask)} ({np.sum(medios_test_mask)/len(pred_geral)*100:.1f}%)\")\n",
    "    print(f\"   Altos:  {np.sum(altos_test_mask)} ({np.sum(altos_test_mask)/len(pred_geral)*100:.1f}%)\")\n",
    "    \n",
    "    # Previs√£o final combinada\n",
    "    pred_final = pred_geral.copy()\n",
    "    \n",
    "    # Aplicar especialista BAIXOS\n",
    "    if modelos['baixos'] is not None and np.sum(baixos_test_mask) > 0:\n",
    "        pred_baixos = modelos['baixos'].predict(X_test[baixos_test_mask])\n",
    "        # Combinar: 60% geral + 40% especialista\n",
    "        pred_final[baixos_test_mask] = 0.6 * pred_final[baixos_test_mask] + 0.4 * pred_baixos\n",
    "        print(f\"   ‚úÖ Aplicado especialista BAIXOS em {np.sum(baixos_test_mask)} pontos\")\n",
    "    \n",
    "    # Aplicar especialista ALTOS\n",
    "    if modelos['altos'] is not None and np.sum(altos_test_mask) > 0:\n",
    "        pred_altos = modelos['altos'].predict(X_test[altos_test_mask])\n",
    "        # Combinar: 60% geral + 40% especialista\n",
    "        pred_final[altos_test_mask] = 0.6 * pred_final[altos_test_mask] + 0.4 * pred_altos\n",
    "        print(f\"   ‚úÖ Aplicado especialista ALTOS em {np.sum(altos_test_mask)} pontos\")\n",
    "    \n",
    "    # 8. AVALIA√á√ÉO\n",
    "    print(f\"\\nüìä AVALIA√á√ÉO:\")\n",
    "    \n",
    "    # Desnormalizar para m√©tricas\n",
    "    pred_geral_real = scaler.inverse_transform(pred_geral.reshape(-1, 1)).flatten()\n",
    "    pred_final_real = scaler.inverse_transform(pred_final.reshape(-1, 1)).flatten()\n",
    "    y_test_real = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # M√©tricas modelo geral\n",
    "    rmse_geral = np.sqrt(mean_squared_error(y_test_real, pred_geral_real))\n",
    "    mae_geral = mean_absolute_error(y_test_real, pred_geral_real)\n",
    "    \n",
    "    # M√©tricas ensemble\n",
    "    rmse_ensemble = np.sqrt(mean_squared_error(y_test_real, pred_final_real))\n",
    "    mae_ensemble = mean_absolute_error(y_test_real, pred_final_real)\n",
    "    \n",
    "    print(f\"   üîò Modelo GERAL:\")\n",
    "    print(f\"      RMSE: {rmse_geral:.4f} | MAE: {mae_geral:.4f}\")\n",
    "    print(f\"   üéØ ENSEMBLE:\")\n",
    "    print(f\"      RMSE: {rmse_ensemble:.4f} | MAE: {mae_ensemble:.4f}\")\n",
    "    \n",
    "    # Melhoria\n",
    "    melhoria_rmse = ((rmse_geral - rmse_ensemble) / rmse_geral) * 100\n",
    "    melhoria_mae = ((mae_geral - mae_ensemble) / mae_geral) * 100\n",
    "    \n",
    "    print(f\"   üöÄ MELHORIA:\")\n",
    "    print(f\"      RMSE: {melhoria_rmse:+.2f}% | MAE: {melhoria_mae:+.2f}%\")\n",
    "    \n",
    "    # 9. SALVAR MODELOS\n",
    "    print(f\"\\nüíæ Salvando modelos...\")\n",
    "    \n",
    "    os.makedirs(\"modelosXGB_ensemble\", exist_ok=True)\n",
    "    os.makedirs(\"scalersXGB\", exist_ok=True)\n",
    "    os.makedirs(\"configsXGB\", exist_ok=True)\n",
    "    \n",
    "    # Salvar ensemble completo\n",
    "    ensemble_data = {\n",
    "        'modelos': modelos,\n",
    "        'scaler': scaler,\n",
    "        'percentis_treino': {'p25': p25, 'p50': p50, 'p75': p75},\n",
    "        'pesos_combinacao': {'geral': 0.6, 'especialista': 0.4}\n",
    "    }\n",
    "    \n",
    "    ensemble_path = f\"modelosXGB_ensemble/ensemble_{nome_comp.lower()}_t{passo}.joblib\"\n",
    "    joblib.dump(ensemble_data, ensemble_path)\n",
    "    \n",
    "    # Salvar scaler (compatibilidade)\n",
    "    scaler_path = f\"scalersXGB/scaler_{nome_comp.lower()}_t{passo}.joblib\"\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    \n",
    "    # Salvar config\n",
    "    config = {\n",
    "        'componente': nome_comp.upper(),\n",
    "        'passo': passo,\n",
    "        'tipo': 'ensemble_especializado',\n",
    "        'look_back': look_back,\n",
    "        'n_features_total': X.shape[1],\n",
    "        'modelos_treinados': list(modelos.keys()),\n",
    "        'performance': {\n",
    "            'rmse_geral': float(rmse_geral),\n",
    "            'mae_geral': float(mae_geral),\n",
    "            'rmse_ensemble': float(rmse_ensemble),\n",
    "            'mae_ensemble': float(mae_ensemble),\n",
    "            'melhoria_rmse_pct': float(melhoria_rmse),\n",
    "            'melhoria_mae_pct': float(melhoria_mae)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config_path = f\"configsXGB/config_{nome_comp.lower()}_t{passo}.json\"\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"   ‚úÖ Ensemble salvo: {ensemble_path}\")\n",
    "    print(f\"   ‚úÖ Config salva: {config_path}\")\n",
    "    \n",
    "    return ensemble_data\n",
    "\n",
    "def treinar_todos_ensembles(passos=[1, 5, 7, 30]):\n",
    "    \"\"\"\n",
    "    Treina ensembles especializados para todos os componentes e horizontes\n",
    "    \"\"\"\n",
    "    print(\"üöÄ TREINAMENTO ENSEMBLE ESPECIALIZADO - TODOS OS MODELOS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    componentes = ['d1', 'd2', 'd3']\n",
    "    total_modelos = len(componentes) * len(passos)\n",
    "    contador = 0\n",
    "    \n",
    "    resultados = {}\n",
    "    \n",
    "    for comp in componentes:\n",
    "        resultados[comp] = {}\n",
    "        \n",
    "        for passo in passos:\n",
    "            contador += 1\n",
    "            print(f\"\\n{'üü¢' * contador}{'‚ö™' * (total_modelos - contador)} PROGRESSO: {contador}/{total_modelos}\")\n",
    "            \n",
    "            try:\n",
    "                ensemble_data = treinar_ensemble_especializado_componente(comp, passo)\n",
    "                \n",
    "                # Extrair m√©tricas\n",
    "                config_path = f\"configsXGB/config_{comp}_t{passo}.json\"\n",
    "                with open(config_path, 'r') as f:\n",
    "                    config = json.load(f)\n",
    "                \n",
    "                resultados[comp][f't+{passo}'] = config['performance']\n",
    "                \n",
    "                print(f\"‚úÖ {comp.upper()} t+{passo} - Melhoria RMSE: {config['performance']['melhoria_rmse_pct']:+.2f}%\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå {comp.upper()} t+{passo} - ERRO: {e}\")\n",
    "                resultados[comp][f't+{passo}'] = {'erro': str(e)}\n",
    "    \n",
    "    # Resumo final\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(\"üìä RESUMO FINAL - ENSEMBLE ESPECIALIZADO\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    melhorias_rmse = []\n",
    "    melhorias_mae = []\n",
    "    \n",
    "    for comp in componentes:\n",
    "        for passo in passos:\n",
    "            key = f't+{passo}'\n",
    "            if key in resultados[comp] and 'melhoria_rmse_pct' in resultados[comp][key]:\n",
    "                perf = resultados[comp][key]\n",
    "                print(f\"{comp.upper()} {key}: RMSE {perf['melhoria_rmse_pct']:+.1f}% | MAE {perf['melhoria_mae_pct']:+.1f}%\")\n",
    "                melhorias_rmse.append(perf['melhoria_rmse_pct'])\n",
    "                melhorias_mae.append(perf['melhoria_mae_pct'])\n",
    "    \n",
    "    if melhorias_rmse:\n",
    "        print(f\"\\nüìà MELHORIA M√âDIA:\")\n",
    "        print(f\"   RMSE: {np.mean(melhorias_rmse):+.2f}% ¬± {np.std(melhorias_rmse):.2f}%\")\n",
    "        print(f\"   MAE:  {np.mean(melhorias_mae):+.2f}% ¬± {np.std(melhorias_mae):.2f}%\")\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Interface de uso\n",
    "print(\"üéØ ENSEMBLE ESPECIALIZADO - IMPLEMENTA√á√ÉO PR√ÅTICA\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üìã FUN√á√ïES DISPON√çVEIS:\")\n",
    "print()\n",
    "print(\"üîπ treinar_ensemble_especializado_componente('d1', passo=1)\")\n",
    "print(\"   ‚Üí Treina ensemble para um componente espec√≠fico\")\n",
    "print()\n",
    "print(\"üîπ treinar_todos_ensembles([1, 5, 7, 30])\")\n",
    "print(\"   ‚Üí Treina ensembles para todos os componentes\")\n",
    "print()\n",
    "print(\"üí° COMO USAR:\")\n",
    "print(\"   1. Execute: treinar_todos_ensembles([1, 5, 7, 30])\")\n",
    "print(\"   2. Aguarde o treinamento (5-15 minutos)\")\n",
    "print(\"   3. Use o c√≥digo de avalia√ß√£o normalmente\")\n",
    "print()\n",
    "print(\"üéØ DIFEREN√áA:\")\n",
    "print(\"   ‚Ä¢ 3 modelos por componente (baixos/m√©dios/altos)\")\n",
    "print(\"   ‚Ä¢ Foco espec√≠fico em picos e depress√µes\")\n",
    "print(\"   ‚Ä¢ Combina√ß√£o inteligente das previs√µes\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37f863ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ TREINAMENTO ENSEMBLE ESPECIALIZADO - TODOS OS MODELOS\n",
      "======================================================================\n",
      "\n",
      "üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 1/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D1 t+1\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-7.7183, 8.8608]\n",
      "üì¶ Dataset: (7873, 5), look_back=5\n",
      "üéØ Percentis: P25=-0.755, P50=-0.021, P75=0.748\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1575 amostras (25.0%)\n",
      "   M√©dios: 3148 amostras (50.0%)\n",
      "   Altos:  1575 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.2174\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.2179\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 394 (25.0%)\n",
      "   M√©dios: 787 (50.0%)\n",
      "   Altos:  394 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 394 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 394 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 0.6245 | MAE: 0.3948\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 0.6357 | MAE: 0.4048\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: -1.80% | MAE: -2.53%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d1_t1.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d1_t1.json\n",
      "‚úÖ D1 t+1 - Melhoria RMSE: -1.80%\n",
      "\n",
      "üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 2/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D1 t+5\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-7.7183, 8.8608]\n",
      "üì¶ Dataset: (7869, 5), look_back=5\n",
      "üéØ Percentis: P25=-0.755, P50=-0.021, P75=0.748\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1574 amostras (25.0%)\n",
      "   M√©dios: 3147 amostras (50.0%)\n",
      "   Altos:  1574 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.3814\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.4094\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 394 (25.0%)\n",
      "   M√©dios: 786 (49.9%)\n",
      "   Altos:  394 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 394 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 394 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 1.3153 | MAE: 0.9287\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 1.4220 | MAE: 1.0416\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: -8.11% | MAE: -12.16%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d1_t5.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d1_t5.json\n",
      "‚úÖ D1 t+5 - Melhoria RMSE: -8.11%\n",
      "\n",
      "üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 3/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D1 t+7\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-7.7183, 8.8608]\n",
      "üì¶ Dataset: (7862, 10), look_back=10\n",
      "üéØ Percentis: P25=-0.755, P50=-0.021, P75=0.748\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1573 amostras (25.0%)\n",
      "   M√©dios: 3143 amostras (50.0%)\n",
      "   Altos:  1573 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.3702\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.3589\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 394 (25.0%)\n",
      "   M√©dios: 785 (49.9%)\n",
      "   Altos:  394 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 394 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 394 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 1.3198 | MAE: 0.9224\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 1.4341 | MAE: 1.0444\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: -8.66% | MAE: -13.23%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d1_t7.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d1_t7.json\n",
      "‚úÖ D1 t+7 - Melhoria RMSE: -8.66%\n",
      "\n",
      "üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 4/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D1 t+30\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-7.7183, 8.8608]\n",
      "üì¶ Dataset: (7839, 10), look_back=10\n",
      "üéØ Percentis: P25=-0.755, P50=-0.021, P75=0.748\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1568 amostras (25.0%)\n",
      "   M√©dios: 3135 amostras (50.0%)\n",
      "   Altos:  1568 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.3401\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.3580\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 392 (25.0%)\n",
      "   M√©dios: 784 (50.0%)\n",
      "   Altos:  392 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 392 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 392 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 1.2896 | MAE: 0.8955\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 1.4012 | MAE: 1.0139\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: -8.66% | MAE: -13.23%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d1_t30.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d1_t30.json\n",
      "‚úÖ D1 t+30 - Melhoria RMSE: -8.66%\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 5/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D2 t+1\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-6.5773, 6.5198]\n",
      "üì¶ Dataset: (7873, 5), look_back=5\n",
      "üéØ Percentis: P25=-0.663, P50=-0.006, P75=0.652\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1575 amostras (25.0%)\n",
      "   M√©dios: 3148 amostras (50.0%)\n",
      "   Altos:  1575 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.1694\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.1694\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 394 (25.0%)\n",
      "   M√©dios: 787 (50.0%)\n",
      "   Altos:  394 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 394 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 394 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 0.2718 | MAE: 0.1835\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 0.2715 | MAE: 0.1855\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: +0.08% | MAE: -1.11%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d2_t1.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d2_t1.json\n",
      "‚úÖ D2 t+1 - Melhoria RMSE: +0.08%\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 6/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D2 t+5\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-6.5773, 6.5198]\n",
      "üì¶ Dataset: (7869, 5), look_back=5\n",
      "üéØ Percentis: P25=-0.664, P50=-0.005, P75=0.652\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1574 amostras (25.0%)\n",
      "   M√©dios: 3147 amostras (50.0%)\n",
      "   Altos:  1574 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.3563\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.3430\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 394 (25.0%)\n",
      "   M√©dios: 786 (49.9%)\n",
      "   Altos:  394 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 394 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 394 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 0.8875 | MAE: 0.6463\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 0.9409 | MAE: 0.7005\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: -6.02% | MAE: -8.38%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d2_t5.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d2_t5.json\n",
      "‚úÖ D2 t+5 - Melhoria RMSE: -6.02%\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 7/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D2 t+7\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-6.5773, 6.5198]\n",
      "üì¶ Dataset: (7862, 10), look_back=10\n",
      "üéØ Percentis: P25=-0.663, P50=-0.005, P75=0.652\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1573 amostras (25.0%)\n",
      "   M√©dios: 3143 amostras (50.0%)\n",
      "   Altos:  1573 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.3151\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.3408\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 394 (25.0%)\n",
      "   M√©dios: 785 (49.9%)\n",
      "   Altos:  394 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 394 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 394 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 0.9576 | MAE: 0.7126\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 1.0406 | MAE: 0.7986\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: -8.67% | MAE: -12.07%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d2_t7.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d2_t7.json\n",
      "‚úÖ D2 t+7 - Melhoria RMSE: -8.67%\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 8/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D2 t+30\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-6.5773, 6.5198]\n",
      "üì¶ Dataset: (7839, 10), look_back=10\n",
      "üéØ Percentis: P25=-0.666, P50=-0.005, P75=0.653\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1568 amostras (25.0%)\n",
      "   M√©dios: 3135 amostras (50.0%)\n",
      "   Altos:  1568 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.3547\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.3975\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 392 (25.0%)\n",
      "   M√©dios: 784 (50.0%)\n",
      "   Altos:  392 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 392 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 392 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 0.9816 | MAE: 0.7207\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 1.0802 | MAE: 0.8130\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: -10.05% | MAE: -12.81%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d2_t30.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d2_t30.json\n",
      "‚úÖ D2 t+30 - Melhoria RMSE: -10.05%\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™ PROGRESSO: 9/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D3 t+1\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-5.7485, 5.2615]\n",
      "üì¶ Dataset: (7873, 5), look_back=5\n",
      "üéØ Percentis: P25=-0.597, P50=0.010, P75=0.588\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1575 amostras (25.0%)\n",
      "   M√©dios: 3148 amostras (50.0%)\n",
      "   Altos:  1575 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.1101\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.1066\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 394 (25.0%)\n",
      "   M√©dios: 787 (50.0%)\n",
      "   Altos:  394 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 394 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 394 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 0.1732 | MAE: 0.1236\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 0.1819 | MAE: 0.1284\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: -5.02% | MAE: -3.95%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d3_t1.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d3_t1.json\n",
      "‚úÖ D3 t+1 - Melhoria RMSE: -5.02%\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™ PROGRESSO: 10/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D3 t+5\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-5.7485, 5.2615]\n",
      "üì¶ Dataset: (7869, 5), look_back=5\n",
      "üéØ Percentis: P25=-0.597, P50=0.011, P75=0.588\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1574 amostras (25.0%)\n",
      "   M√©dios: 3147 amostras (50.0%)\n",
      "   Altos:  1574 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.2272\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.2294\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 394 (25.0%)\n",
      "   M√©dios: 786 (49.9%)\n",
      "   Altos:  394 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 394 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 394 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 0.4927 | MAE: 0.3483\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 0.5192 | MAE: 0.3690\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: -5.38% | MAE: -5.94%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d3_t5.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d3_t5.json\n",
      "‚úÖ D3 t+5 - Melhoria RMSE: -5.38%\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™ PROGRESSO: 11/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D3 t+7\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-5.7485, 5.2615]\n",
      "üì¶ Dataset: (7862, 10), look_back=10\n",
      "üéØ Percentis: P25=-0.596, P50=0.011, P75=0.588\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1573 amostras (25.0%)\n",
      "   M√©dios: 3143 amostras (50.0%)\n",
      "   Altos:  1573 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.2668\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.2745\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 394 (25.0%)\n",
      "   M√©dios: 785 (49.9%)\n",
      "   Altos:  394 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 394 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 394 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 0.6247 | MAE: 0.4281\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 0.6532 | MAE: 0.4588\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: -4.57% | MAE: -7.17%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d3_t7.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d3_t7.json\n",
      "‚úÖ D3 t+7 - Melhoria RMSE: -4.57%\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢ PROGRESSO: 12/12\n",
      "üéØ ENSEMBLE ESPECIALIZADO - D3 t+30\n",
      "============================================================\n",
      "üìä Dados carregados: 7878 pontos\n",
      "   Range: [-5.7485, 5.2615]\n",
      "üì¶ Dataset: (7839, 10), look_back=10\n",
      "üéØ Percentis: P25=-0.598, P50=0.009, P75=0.587\n",
      "üìä Distribui√ß√£o:\n",
      "   Baixos: 1568 amostras (25.0%)\n",
      "   M√©dios: 3135 amostras (50.0%)\n",
      "   Altos:  1568 amostras (25.0%)\n",
      "\n",
      "üîΩ Treinando especialista BAIXOS...\n",
      "      RMSE treino: 0.3338\n",
      "\n",
      "üîº Treinando especialista ALTOS...\n",
      "      RMSE treino: 0.3340\n",
      "\n",
      "‚öñÔ∏è Treinando modelo GERAL...\n",
      "\n",
      "üîÄ Fazendo previs√£o ensemble...\n",
      "üìä Distribui√ß√£o no teste:\n",
      "   Baixos: 392 (25.0%)\n",
      "   M√©dios: 784 (50.0%)\n",
      "   Altos:  392 (25.0%)\n",
      "   ‚úÖ Aplicado especialista BAIXOS em 392 pontos\n",
      "   ‚úÖ Aplicado especialista ALTOS em 392 pontos\n",
      "\n",
      "üìä AVALIA√á√ÉO:\n",
      "   üîò Modelo GERAL:\n",
      "      RMSE: 0.8603 | MAE: 0.6242\n",
      "   üéØ ENSEMBLE:\n",
      "      RMSE: 0.9427 | MAE: 0.6996\n",
      "   üöÄ MELHORIA:\n",
      "      RMSE: -9.57% | MAE: -12.08%\n",
      "\n",
      "üíæ Salvando modelos...\n",
      "   ‚úÖ Ensemble salvo: modelosXGB_ensemble/ensemble_d3_t30.joblib\n",
      "   ‚úÖ Config salva: configsXGB/config_d3_t30.json\n",
      "‚úÖ D3 t+30 - Melhoria RMSE: -9.57%\n",
      "\n",
      "======================================================================\n",
      "üìä RESUMO FINAL - ENSEMBLE ESPECIALIZADO\n",
      "======================================================================\n",
      "D1 t+1: RMSE -1.8% | MAE -2.5%\n",
      "D1 t+5: RMSE -8.1% | MAE -12.2%\n",
      "D1 t+7: RMSE -8.7% | MAE -13.2%\n",
      "D1 t+30: RMSE -8.7% | MAE -13.2%\n",
      "D2 t+1: RMSE +0.1% | MAE -1.1%\n",
      "D2 t+5: RMSE -6.0% | MAE -8.4%\n",
      "D2 t+7: RMSE -8.7% | MAE -12.1%\n",
      "D2 t+30: RMSE -10.1% | MAE -12.8%\n",
      "D3 t+1: RMSE -5.0% | MAE -3.9%\n",
      "D3 t+5: RMSE -5.4% | MAE -5.9%\n",
      "D3 t+7: RMSE -4.6% | MAE -7.2%\n",
      "D3 t+30: RMSE -9.6% | MAE -12.1%\n",
      "\n",
      "üìà MELHORIA M√âDIA:\n",
      "   RMSE: -6.37% ¬± 3.04%\n",
      "   MAE:  -8.72% ¬± 4.29%\n"
     ]
    }
   ],
   "source": [
    "# Treinar todos os modelos ensemble\n",
    "resultados = treinar_todos_ensembles([1, 5, 7, 30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
