{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d632a9d",
   "metadata": {},
   "source": [
    "## Gerando os componentes MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ced7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† TREINAMENTO MLP PARA COMPONENTES\n",
      "==================================================\n",
      "üìã Fun√ß√µes dispon√≠veis:\n",
      "\n",
      "üîπ treinar_mlp_componente('d1', passo=1)\n",
      "   ‚Üí Treina um modelo MLP espec√≠fico\n",
      "\n",
      "üîπ treinar_todos_componentes_mlp([1, 5, 7, 30])\n",
      "   ‚Üí Treina todos os modelos MLP para todos os horizontes\n",
      "\n",
      "üîπ comparar_arquiteturas_mlp('d1', passo=1)\n",
      "   ‚Üí Testa diferentes arquiteturas para encontrar a melhor\n",
      "\n",
      "üí° CARACTER√çSTICAS DOS MODELOS MLP:\n",
      "   ‚Ä¢ Apenas sequ√™ncias temporais (consistente com LSTM/XGBoost)\n",
      "   ‚Ä¢ Look_back: 5 para t+1,t+5 | 10 para demais\n",
      "   ‚Ä¢ Scaler: RobustScaler\n",
      "   ‚Ä¢ Modelo: MLPRegressor com arquitetura adaptativa\n",
      "   ‚Ä¢ Early stopping e regulariza√ß√£o L2\n",
      "   ‚Ä¢ Otimizador: Adam com learning rate adaptativo\n",
      "\n",
      "üéØ EXEMPLO DE USO:\n",
      "   # Treinar um modelo espec√≠fico\n",
      "   resultado = treinar_mlp_componente('d1', 1)\n",
      "\n",
      "   # Treinar todos os modelos\n",
      "   resultados = treinar_todos_componentes_mlp([1, 5, 7, 30])\n",
      "\n",
      "   # Comparar arquiteturas\n",
      "   melhores = comparar_arquiteturas_mlp('d1', 1)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def criar_dataset_simples(series, look_back=5, passo=1):\n",
    "    \"\"\"\n",
    "    Criar dataset SIMPLES - apenas sequ√™ncia temporal (igual ao LSTM e XGBoost)\n",
    "    SEM features engineering\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - look_back - passo + 1):\n",
    "        # Apenas a sequ√™ncia temporal\n",
    "        sequencia = series[i:i + look_back]\n",
    "        target = series[i + look_back + passo - 1]\n",
    "        \n",
    "        X.append(sequencia.flatten())\n",
    "        y.append(target[0])  # target √© array, pegar valor\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def treinar_mlp_componente(nome_comp, passo=1, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Treinar modelo MLP para um componente espec√≠fico\n",
    "    Usando APENAS sequ√™ncias temporais (sem features engineering)\n",
    "    \"\"\"\n",
    "    print(f\"üß† TREINANDO MLP - {nome_comp.upper()} para t+{passo}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Carregar dados\n",
    "    print(f\"üìä 1. Carregando dados {nome_comp.upper()}...\")\n",
    "    comp_file = f\"{nome_comp.upper()}_component.csv\"\n",
    "    if not Path(comp_file).exists():\n",
    "        raise FileNotFoundError(f\"Arquivo n√£o encontrado: {comp_file}\")\n",
    "    \n",
    "    df = pd.read_csv(comp_file)\n",
    "    if nome_comp.upper() not in df.columns:\n",
    "        raise ValueError(f\"Coluna {nome_comp.upper()} n√£o encontrada em {comp_file}\")\n",
    "    \n",
    "    data = df[nome_comp.upper()].values.reshape(-1, 1)\n",
    "    print(f\"   ‚úÖ Dados carregados: {len(data)} pontos\")\n",
    "    print(f\"   üìà Range: [{data.min():.4f}, {data.max():.4f}]\")\n",
    "    print(f\"   üìä Std: {np.std(data):.4f}\")\n",
    "    \n",
    "    # 2. Normaliza√ß√£o\n",
    "    print(f\"\\nüîß 2. Aplicando normaliza√ß√£o...\")\n",
    "    scaler = RobustScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    print(f\"   ‚úÖ Scaler: RobustScaler\")\n",
    "    print(f\"   üìà Range normalizado: [{data_scaled.min():.4f}, {data_scaled.max():.4f}]\")\n",
    "    \n",
    "    # 3. Criar dataset\n",
    "    print(f\"\\nüì¶ 3. Criando dataset...\")\n",
    "    look_back = 5 if passo in [1, 5] else 10  # Regra original\n",
    "    print(f\"   üìè Look_back: {look_back}\")\n",
    "    print(f\"   üéØ Passo de previs√£o: {passo}\")\n",
    "    \n",
    "    X, y = criar_dataset_simples(data_scaled, look_back, passo)\n",
    "    print(f\"   ‚úÖ Dataset criado:\")\n",
    "    print(f\"      X shape: {X.shape} (apenas sequ√™ncias temporais)\")\n",
    "    print(f\"      y shape: {y.shape}\")\n",
    "    print(f\"      Features: {X.shape[1]} (= look_back, SEM features engineering)\")\n",
    "    \n",
    "    # 4. Divis√£o treino/teste\n",
    "    print(f\"\\n‚úÇÔ∏è 4. Dividindo dados...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, shuffle=False\n",
    "    )\n",
    "    print(f\"   ‚úÖ Treino: {X_train.shape[0]} amostras\")\n",
    "    print(f\"   ‚úÖ Teste: {X_test.shape[0]} amostras\")\n",
    "    \n",
    "    # 5. Configurar MLP\n",
    "    print(f\"\\nüß† 5. Configurando MLP...\")\n",
    "    \n",
    "    # Arquitetura adaptativa baseada no look_back\n",
    "    if look_back == 5:\n",
    "        # Para look_back menor, arquitetura mais simples\n",
    "        hidden_layers = (64, 32, 16)\n",
    "    else:\n",
    "        # Para look_back maior, arquitetura mais complexa\n",
    "        hidden_layers = (128, 64, 32, 16)\n",
    "    \n",
    "    mlp_params = {\n",
    "        'hidden_layer_sizes': hidden_layers,\n",
    "        'activation': 'relu',\n",
    "        'solver': 'adam',\n",
    "        'alpha': 0.001,  # Regulariza√ß√£o L2\n",
    "        'learning_rate': 'adaptive',\n",
    "        'learning_rate_init': 0.001,\n",
    "        'max_iter': 500,\n",
    "        'early_stopping': True,\n",
    "        'validation_fraction': 0.1,\n",
    "        'n_iter_no_change': 20,\n",
    "        'random_state': random_state,\n",
    "        'tol': 1e-4\n",
    "    }\n",
    "    \n",
    "    print(f\"   üìã Par√¢metros MLP:\")\n",
    "    print(f\"      Arquitetura: {hidden_layers}\")\n",
    "    print(f\"      Ativa√ß√£o: {mlp_params['activation']}\")\n",
    "    print(f\"      Solver: {mlp_params['solver']}\")\n",
    "    print(f\"      Learning rate: {mlp_params['learning_rate_init']}\")\n",
    "    print(f\"      Regulariza√ß√£o: {mlp_params['alpha']}\")\n",
    "    print(f\"      Max √©pocas: {mlp_params['max_iter']}\")\n",
    "    print(f\"      Early stopping: {mlp_params['early_stopping']}\")\n",
    "    \n",
    "    # 6. Treinar modelo\n",
    "    print(f\"\\nüöÄ 6. Treinando modelo...\")\n",
    "    modelo = MLPRegressor(**mlp_params)\n",
    "    \n",
    "    # Treinar com verbose para acompanhar\n",
    "    import time\n",
    "    inicio = time.time()\n",
    "    modelo.fit(X_train, y_train)\n",
    "    tempo_treino = time.time() - inicio\n",
    "    \n",
    "    print(f\"   ‚úÖ Treinamento conclu√≠do em {tempo_treino:.1f}s!\")\n",
    "    print(f\"   üìä Itera√ß√µes realizadas: {modelo.n_iter_}\")\n",
    "    print(f\"   üìà Loss final: {modelo.loss_:.6f}\")\n",
    "    \n",
    "    # 7. Avaliar modelo\n",
    "    print(f\"\\nüìä 7. Avaliando performance...\")\n",
    "    \n",
    "    # Previs√µes\n",
    "    y_pred_train = modelo.predict(X_train)\n",
    "    y_pred_test = modelo.predict(X_test)\n",
    "    \n",
    "    # Desnormalizar para m√©tricas\n",
    "    y_train_real = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "    y_test_real = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "    y_pred_train_real = scaler.inverse_transform(y_pred_train.reshape(-1, 1)).flatten()\n",
    "    y_pred_test_real = scaler.inverse_transform(y_pred_test.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # M√©tricas treino\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train_real, y_pred_train_real))\n",
    "    mae_train = mean_absolute_error(y_train_real, y_pred_train_real)\n",
    "    \n",
    "    # M√©tricas teste\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test_real, y_pred_test_real))\n",
    "    mae_test = mean_absolute_error(y_test_real, y_pred_test_real)\n",
    "    \n",
    "    print(f\"   üìà TREINO:\")\n",
    "    print(f\"      RMSE: {rmse_train:.4f}\")\n",
    "    print(f\"      MAE:  {mae_train:.4f}\")\n",
    "    print(f\"   üìà TESTE:\")\n",
    "    print(f\"      RMSE: {rmse_test:.4f}\")\n",
    "    print(f\"      MAE:  {mae_test:.4f}\")\n",
    "    \n",
    "    # Verificar overfitting\n",
    "    overfitting_ratio = rmse_test / rmse_train\n",
    "    if overfitting_ratio > 1.5:\n",
    "        print(f\"   ‚ö†Ô∏è Poss√≠vel overfitting (ratio: {overfitting_ratio:.2f})\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Sem overfitting (ratio: {overfitting_ratio:.2f})\")\n",
    "    \n",
    "    # Verificar converg√™ncia\n",
    "    if modelo.n_iter_ >= mlp_params['max_iter']:\n",
    "        print(f\"   ‚ö†Ô∏è Modelo n√£o convergiu (atingiu max_iter)\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Modelo convergiu em {modelo.n_iter_} itera√ß√µes\")\n",
    "    \n",
    "    # 8. Salvar arquivos\n",
    "    print(f\"\\nüíæ 8. Salvando arquivos...\")\n",
    "    \n",
    "    # Criar diret√≥rios\n",
    "    os.makedirs(\"modelosMLP\", exist_ok=True)\n",
    "    os.makedirs(\"scalersMLP\", exist_ok=True)\n",
    "    os.makedirs(\"configsMLP\", exist_ok=True)\n",
    "    \n",
    "    # Salvar modelo\n",
    "    modelo_path = f\"modelosMLP/mlp_{nome_comp.lower()}_t{passo}.joblib\"\n",
    "    joblib.dump(modelo, modelo_path)\n",
    "    print(f\"   ‚úÖ Modelo salvo: {modelo_path}\")\n",
    "    \n",
    "    # Salvar scaler\n",
    "    scaler_path = f\"scalersMLP/scaler_{nome_comp.lower()}_t{passo}.joblib\"\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f\"   ‚úÖ Scaler salvo: {scaler_path}\")\n",
    "    \n",
    "    # Salvar configura√ß√£o\n",
    "    config = {\n",
    "        'componente': nome_comp.upper(),\n",
    "        'passo': passo,\n",
    "        'look_back': look_back,\n",
    "        'n_features_total': X.shape[1],\n",
    "        'n_features_sequencia': look_back,\n",
    "        'n_features_engineering': 0,  # SEM features engineering\n",
    "        'scaler_type': 'RobustScaler',\n",
    "        'model_type': 'MLPRegressor',\n",
    "        'mlp_params': mlp_params,\n",
    "        'arquitetura': {\n",
    "            'hidden_layers': hidden_layers,\n",
    "            'total_parameters': sum([layer * next_layer for layer, next_layer in \n",
    "                                   zip([X.shape[1]] + list(hidden_layers), \n",
    "                                       list(hidden_layers) + [1])]),\n",
    "            'activation': mlp_params['activation'],\n",
    "            'solver': mlp_params['solver']\n",
    "        },\n",
    "        'dataset_info': {\n",
    "            'total_samples': len(X),\n",
    "            'train_samples': len(X_train),\n",
    "            'test_samples': len(X_test),\n",
    "            'data_range_original': [float(data.min()), float(data.max())],\n",
    "            'data_range_scaled': [float(data_scaled.min()), float(data_scaled.max())]\n",
    "        },\n",
    "        'training_info': {\n",
    "            'tempo_treino_segundos': float(tempo_treino),\n",
    "            'iteracoes_realizadas': int(modelo.n_iter_),\n",
    "            'loss_final': float(modelo.loss_),\n",
    "            'convergiu': bool(modelo.n_iter_ < mlp_params['max_iter'])\n",
    "        },\n",
    "        'performance': {\n",
    "            'rmse_train': float(rmse_train),\n",
    "            'mae_train': float(mae_train),\n",
    "            'rmse_test': float(rmse_test),\n",
    "            'mae_test': float(mae_test),\n",
    "            'overfitting_ratio': float(overfitting_ratio)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config_path = f\"configsMLP/config_{nome_comp.lower()}_t{passo}.json\"\n",
    "    with open(config_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"   ‚úÖ Config salva: {config_path}\")\n",
    "    \n",
    "    # 9. Teste de sanidade\n",
    "    print(f\"\\nüß™ 9. Teste de sanidade...\")\n",
    "    \n",
    "    # Carregar modelo salvo e testar\n",
    "    modelo_carregado = joblib.load(modelo_path)\n",
    "    scaler_carregado = joblib.load(scaler_path)\n",
    "    \n",
    "    # Teste com uma amostra\n",
    "    amostra_teste = X_test[:5]  # 5 amostras\n",
    "    pred_teste = modelo_carregado.predict(amostra_teste)\n",
    "    pred_teste_real = scaler_carregado.inverse_transform(pred_teste.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    print(f\"   ‚úÖ Modelo carregado e testado:\")\n",
    "    print(f\"      Amostras teste: {len(amostra_teste)}\")\n",
    "    print(f\"      Previs√µes (normalizado): {pred_teste[:3]}\")\n",
    "    print(f\"      Previs√µes (real): {pred_teste_real[:3]}\")\n",
    "    print(f\"      Variabilidade: {np.std(pred_teste_real):.4f}\")\n",
    "    \n",
    "    print(f\"\\nüéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\")\n",
    "    print(f\"   üìÅ Arquivos salvos:\")\n",
    "    print(f\"      - {modelo_path}\")\n",
    "    print(f\"      - {scaler_path}\")\n",
    "    print(f\"      - {config_path}\")\n",
    "    \n",
    "    return {\n",
    "        'modelo': modelo,\n",
    "        'scaler': scaler,\n",
    "        'config': config,\n",
    "        'performance': {\n",
    "            'rmse_test': rmse_test,\n",
    "            'mae_test': mae_test,\n",
    "            'overfitting_ratio': overfitting_ratio,\n",
    "            'tempo_treino': tempo_treino,\n",
    "            'convergiu': modelo.n_iter_ < mlp_params['max_iter']\n",
    "        }\n",
    "    }\n",
    "\n",
    "def treinar_todos_componentes_mlp(passos=[1, 5, 7, 30]):\n",
    "    \"\"\"\n",
    "    Treinar modelos MLP para todos os componentes D1, D2, D3\n",
    "    em todos os horizontes de previs√£o\n",
    "    \"\"\"\n",
    "    print(\"üß† TREINAMENTO COMPLETO - MLP SIMPLES\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"üìã Componentes: D1, D2, D3\")\n",
    "    print(f\"üéØ Horizontes: {passos}\")\n",
    "    print(f\"üîß Abordagem: Apenas sequ√™ncias temporais (sem features)\")\n",
    "    print(f\"üß† Modelo: Multi-Layer Perceptron (MLP)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    resultados = {}\n",
    "    componentes = ['d1', 'd2', 'd3']\n",
    "    \n",
    "    total_modelos = len(componentes) * len(passos)\n",
    "    contador = 0\n",
    "    \n",
    "    import time\n",
    "    inicio_total = time.time()\n",
    "    \n",
    "    for comp in componentes:\n",
    "        resultados[comp] = {}\n",
    "        \n",
    "        for passo in passos:\n",
    "            contador += 1\n",
    "            print(f\"\\n{'üü¢' * contador}{'‚ö™' * (total_modelos - contador)} PROGRESSO: {contador}/{total_modelos}\")\n",
    "            print(f\"üéØ Treinando {comp.upper()} para t+{passo}\")\n",
    "            \n",
    "            try:\n",
    "                resultado = treinar_mlp_componente(comp, passo)\n",
    "                resultados[comp][f't+{passo}'] = resultado['performance']\n",
    "                \n",
    "                convergiu = \"‚úÖ Convergiu\" if resultado['performance']['convergiu'] else \"‚ö†Ô∏è N√£o convergiu\"\n",
    "                print(f\"‚úÖ {comp.upper()} t+{passo} - SUCESSO (RMSE: {resultado['performance']['rmse_test']:.4f}) - {convergiu}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå {comp.upper()} t+{passo} - ERRO: {e}\")\n",
    "                resultados[comp][f't+{passo}'] = {'erro': str(e)}\n",
    "    \n",
    "    tempo_total = time.time() - inicio_total\n",
    "    \n",
    "    # Resumo final\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(\"üìä RESUMO FINAL DO TREINAMENTO MLP\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"‚è±Ô∏è Tempo total: {tempo_total/60:.1f} minutos\")\n",
    "    \n",
    "    print(f\"{'Componente':<12} {'Horizonte':<10} {'RMSE':<8} {'MAE':<8} {'Convergiu':<10} {'Status':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    sucessos = 0\n",
    "    falhas = 0\n",
    "    nao_convergiu = 0\n",
    "    \n",
    "    for comp in componentes:\n",
    "        for passo in passos:\n",
    "            key = f't+{passo}'\n",
    "            if key in resultados[comp]:\n",
    "                if 'erro' in resultados[comp][key]:\n",
    "                    print(f\"{comp.upper():<12} {key:<10} {'N/A':<8} {'N/A':<8} {'N/A':<10} {'ERRO':<10}\")\n",
    "                    falhas += 1\n",
    "                else:\n",
    "                    perf = resultados[comp][key]\n",
    "                    rmse = perf['rmse_test']\n",
    "                    mae = perf['mae_test']\n",
    "                    convergiu = \"Sim\" if perf['convergiu'] else \"N√£o\"\n",
    "                    if not perf['convergiu']:\n",
    "                        nao_convergiu += 1\n",
    "                    \n",
    "                    print(f\"{comp.upper():<12} {key:<10} {rmse:<8.4f} {mae:<8.4f} {convergiu:<10} {'OK':<10}\")\n",
    "                    sucessos += 1\n",
    "    \n",
    "    print(f\"\\nüìä ESTAT√çSTICAS:\")\n",
    "    print(f\"   ‚úÖ Sucessos: {sucessos}\")\n",
    "    print(f\"   ‚ùå Falhas: {falhas}\")\n",
    "    print(f\"   ‚ö†Ô∏è N√£o convergiram: {nao_convergiu}\")\n",
    "    print(f\"   üìà Taxa de sucesso: {(sucessos/(sucessos+falhas)*100):.1f}%\")\n",
    "    \n",
    "    if nao_convergiu > 0:\n",
    "        print(f\"\\nüí° DICA: {nao_convergiu} modelos n√£o convergiram.\")\n",
    "        print(f\"   Considere aumentar max_iter ou ajustar learning_rate.\")\n",
    "    \n",
    "    # Salvar resumo\n",
    "    resumo_path = \"configsMLP/resumo_treinamento_mlp.json\"\n",
    "    resumo = {\n",
    "        'data_treinamento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'abordagem': 'MLP simples - apenas sequ√™ncias temporais',\n",
    "        'modelo_tipo': 'Multi-Layer Perceptron (MLPRegressor)',\n",
    "        'componentes': componentes,\n",
    "        'horizontes': passos,\n",
    "        'total_modelos': total_modelos,\n",
    "        'tempo_total_minutos': tempo_total / 60,\n",
    "        'sucessos': sucessos,\n",
    "        'falhas': falhas,\n",
    "        'nao_convergiram': nao_convergiu,\n",
    "        'resultados': resultados\n",
    "    }\n",
    "    \n",
    "    os.makedirs(\"configsMLP\", exist_ok=True)\n",
    "    with open(resumo_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(resumo, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Resumo salvo: {resumo_path}\")\n",
    "    \n",
    "    if sucessos == total_modelos:\n",
    "        print(f\"\\nüéâ TODOS OS MODELOS MLP TREINADOS COM SUCESSO!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Alguns modelos falharam. Verifique os logs acima.\")\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "def comparar_arquiteturas_mlp(nome_comp='d1', passo=1):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para testar diferentes arquiteturas MLP e encontrar a melhor\n",
    "    \"\"\"\n",
    "    print(f\"üî¨ TESTE DE ARQUITETURAS MLP - {nome_comp.upper()} t+{passo}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Arquiteturas a testar\n",
    "    arquiteturas = {\n",
    "        'simples': (32, 16),\n",
    "        'media': (64, 32, 16),\n",
    "        'complexa': (128, 64, 32, 16),\n",
    "        'profunda': (128, 128, 64, 64, 32, 16),\n",
    "        'larga': (256, 128, 64)\n",
    "    }\n",
    "    \n",
    "    # Carregar dados\n",
    "    comp_file = f\"{nome_comp.upper()}_component.csv\"\n",
    "    df = pd.read_csv(comp_file)\n",
    "    data = df[nome_comp.upper()].values.reshape(-1, 1)\n",
    "    \n",
    "    scaler = RobustScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "    look_back = 5 if passo in [1, 5] else 10\n",
    "    X, y = criar_dataset_simples(data_scaled, look_back, passo)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "    resultados_arq = {}\n",
    "    \n",
    "    for nome_arq, hidden_layers in arquiteturas.items():\n",
    "        print(f\"\\nüß† Testando arquitetura '{nome_arq}': {hidden_layers}\")\n",
    "        \n",
    "        try:\n",
    "            modelo = MLPRegressor(\n",
    "                hidden_layer_sizes=hidden_layers,\n",
    "                activation='relu',\n",
    "                solver='adam',\n",
    "                alpha=0.001,\n",
    "                learning_rate='adaptive',\n",
    "                learning_rate_init=0.001,\n",
    "                max_iter=300,\n",
    "                early_stopping=True,\n",
    "                validation_fraction=0.1,\n",
    "                n_iter_no_change=15,\n",
    "                random_state=42,\n",
    "                tol=1e-4\n",
    "            )\n",
    "            \n",
    "            inicio = time.time()\n",
    "            modelo.fit(X_train, y_train)\n",
    "            tempo_treino = time.time() - inicio\n",
    "            \n",
    "            # Avaliar\n",
    "            y_pred_test = modelo.predict(X_test)\n",
    "            y_test_real = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "            y_pred_real = scaler.inverse_transform(y_pred_test.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            rmse = np.sqrt(mean_squared_error(y_test_real, y_pred_real))\n",
    "            mae = mean_absolute_error(y_test_real, y_pred_real)\n",
    "            \n",
    "            # Calcular n√∫mero de par√¢metros\n",
    "            n_params = sum([layer * next_layer for layer, next_layer in \n",
    "                           zip([X.shape[1]] + list(hidden_layers), \n",
    "                               list(hidden_layers) + [1])])\n",
    "            \n",
    "            resultados_arq[nome_arq] = {\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'tempo_treino': tempo_treino,\n",
    "                'n_parametros': n_params,\n",
    "                'convergiu': modelo.n_iter_ < 300,\n",
    "                'iteracoes': modelo.n_iter_,\n",
    "                'loss_final': modelo.loss_\n",
    "            }\n",
    "            \n",
    "            status = \"‚úÖ Convergiu\" if modelo.n_iter_ < 300 else \"‚ö†Ô∏è N√£o convergiu\"\n",
    "            print(f\"   RMSE: {rmse:.4f} | MAE: {mae:.4f} | Params: {n_params} | {status}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Erro: {e}\")\n",
    "            resultados_arq[nome_arq] = {'erro': str(e)}\n",
    "    \n",
    "    # Encontrar melhor arquitetura\n",
    "    print(f\"\\nüèÜ RANKING DAS ARQUITETURAS:\")\n",
    "    print(f\"{'Arquitetura':<12} {'RMSE':<8} {'MAE':<8} {'Params':<8} {'Tempo':<8} {'Status'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    arquiteturas_validas = {k: v for k, v in resultados_arq.items() if 'erro' not in v}\n",
    "    ranking = sorted(arquiteturas_validas.items(), key=lambda x: x[1]['rmse'])\n",
    "    \n",
    "    for i, (nome, resultado) in enumerate(ranking):\n",
    "        emoji = \"ü•á\" if i == 0 else \"ü•à\" if i == 1 else \"ü•â\" if i == 2 else \"  \"\n",
    "        status = \"Conv.\" if resultado['convergiu'] else \"N.Conv.\"\n",
    "        print(f\"{emoji} {nome:<10} {resultado['rmse']:<8.4f} {resultado['mae']:<8.4f} \"\n",
    "              f\"{resultado['n_parametros']:<8} {resultado['tempo_treino']:<8.1f}s {status}\")\n",
    "    \n",
    "    if ranking:\n",
    "        melhor = ranking[0]\n",
    "        print(f\"\\nüéØ MELHOR ARQUITETURA: {melhor[0]} - {arquiteturas[melhor[0]]}\")\n",
    "    \n",
    "    return resultados_arq\n",
    "\n",
    "# Interface de uso\n",
    "print(\"üß† TREINAMENTO MLP PARA COMPONENTES\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üìã Fun√ß√µes dispon√≠veis:\")\n",
    "print()\n",
    "print(\"üîπ treinar_mlp_componente('d1', passo=1)\")\n",
    "print(\"   ‚Üí Treina um modelo MLP espec√≠fico\")\n",
    "print()\n",
    "print(\"üîπ treinar_todos_componentes_mlp([1, 5, 7, 30])\")\n",
    "print(\"   ‚Üí Treina todos os modelos MLP para todos os horizontes\")\n",
    "print()\n",
    "print(\"üîπ comparar_arquiteturas_mlp('d1', passo=1)\")\n",
    "print(\"   ‚Üí Testa diferentes arquiteturas para encontrar a melhor\")\n",
    "print()\n",
    "print(\"üí° CARACTER√çSTICAS DOS MODELOS MLP:\")\n",
    "print(\"   ‚Ä¢ Apenas sequ√™ncias temporais (consistente com LSTM/XGBoost)\")\n",
    "print(\"   ‚Ä¢ Look_back: 5 para t+1,t+5 | 10 para demais\")\n",
    "print(\"   ‚Ä¢ Scaler: RobustScaler\")\n",
    "print(\"   ‚Ä¢ Modelo: MLPRegressor com arquitetura adaptativa\")\n",
    "print(\"   ‚Ä¢ Early stopping e regulariza√ß√£o L2\")\n",
    "print(\"   ‚Ä¢ Otimizador: Adam com learning rate adaptativo\")\n",
    "print()\n",
    "print(\"üéØ EXEMPLO DE USO:\")\n",
    "print(\"   # Treinar um modelo espec√≠fico\")\n",
    "print(\"   resultado = treinar_mlp_componente('d1', 1)\")\n",
    "print()\n",
    "print(\"   # Treinar todos os modelos\")\n",
    "print(\"   resultados = treinar_todos_componentes_mlp([1, 5, 7, 30])\")\n",
    "print()\n",
    "print(\"   # Comparar arquiteturas\")\n",
    "print(\"   melhores = comparar_arquiteturas_mlp('d1', 1)\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b02f026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† TREINAMENTO COMPLETO - MLP SIMPLES\n",
      "======================================================================\n",
      "üìã Componentes: D1, D2, D3\n",
      "üéØ Horizontes: [1, 5, 7, 30]\n",
      "üîß Abordagem: Apenas sequ√™ncias temporais (sem features)\n",
      "üß† Modelo: Multi-Layer Perceptron (MLP)\n",
      "======================================================================\n",
      "\n",
      "üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 1/12\n",
      "üéØ Treinando D1 para t+1\n",
      "üß† TREINANDO MLP - D1 para t+1\n",
      "============================================================\n",
      "üìä 1. Carregando dados D1...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-7.7183, 8.8608]\n",
      "   üìä Std: 1.3112\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.4508, 6.2790]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 1\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7873, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7873,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6298 amostras\n",
      "   ‚úÖ Teste: 1575 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 4.0s!\n",
      "   üìä Itera√ß√µes realizadas: 207\n",
      "   üìà Loss final: 0.008411\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.1782\n",
      "      MAE:  0.1159\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.2813\n",
      "      MAE:  0.1342\n",
      "   ‚ö†Ô∏è Poss√≠vel overfitting (ratio: 1.58)\n",
      "   ‚úÖ Modelo convergiu em 207 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d1_t1.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d1_t1.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d1_t1.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [ 0.6369457  -0.62661157  0.74810727]\n",
      "      Previs√µes (real): [ 0.88621416 -0.89972904  1.04333268]\n",
      "      Variabilidade: 1.4371\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d1_t1.joblib\n",
      "      - scalersMLP/scaler_d1_t1.joblib\n",
      "      - configsMLP/config_d1_t1.json\n",
      "‚úÖ D1 t+1 - SUCESSO (RMSE: 0.2813) - ‚úÖ Convergiu\n",
      "\n",
      "üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 2/12\n",
      "üéØ Treinando D1 para t+5\n",
      "üß† TREINANDO MLP - D1 para t+5\n",
      "============================================================\n",
      "üìä 1. Carregando dados D1...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-7.7183, 8.8608]\n",
      "   üìä Std: 1.3112\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.4508, 6.2790]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 5\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7869, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7869,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6295 amostras\n",
      "   ‚úÖ Teste: 1574 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 0.7s!\n",
      "   üìä Itera√ß√µes realizadas: 40\n",
      "   üìà Loss final: 0.415637\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 1.3101\n",
      "      MAE:  0.9776\n",
      "   üìà TESTE:\n",
      "      RMSE: 1.2700\n",
      "      MAE:  0.8554\n",
      "   ‚úÖ Sem overfitting (ratio: 0.97)\n",
      "   ‚úÖ Modelo convergiu em 40 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d1_t5.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d1_t5.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d1_t5.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.16101122 -0.06266556 -0.02542811]\n",
      "      Previs√µes (real): [-0.24163796 -0.10263375 -0.05000142]\n",
      "      Variabilidade: 0.0928\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d1_t5.joblib\n",
      "      - scalersMLP/scaler_d1_t5.joblib\n",
      "      - configsMLP/config_d1_t5.json\n",
      "‚úÖ D1 t+5 - SUCESSO (RMSE: 1.2700) - ‚úÖ Convergiu\n",
      "\n",
      "üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 3/12\n",
      "üéØ Treinando D1 para t+7\n",
      "üß† TREINANDO MLP - D1 para t+7\n",
      "============================================================\n",
      "üìä 1. Carregando dados D1...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-7.7183, 8.8608]\n",
      "   üìä Std: 1.3112\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.4508, 6.2790]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 7\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7862, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7862,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6289 amostras\n",
      "   ‚úÖ Teste: 1573 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (128, 64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 0.8s!\n",
      "   üìä Itera√ß√µes realizadas: 24\n",
      "   üìà Loss final: 0.394592\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 1.3180\n",
      "      MAE:  0.9822\n",
      "   üìà TESTE:\n",
      "      RMSE: 1.2542\n",
      "      MAE:  0.8406\n",
      "   ‚úÖ Sem overfitting (ratio: 0.95)\n",
      "   ‚úÖ Modelo convergiu em 24 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d1_t7.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d1_t7.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d1_t7.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [ 0.0405581   0.01855272 -0.02697256]\n",
      "      Previs√µes (real): [ 0.04326513  0.01216217 -0.05218438]\n",
      "      Variabilidade: 0.0521\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d1_t7.joblib\n",
      "      - scalersMLP/scaler_d1_t7.joblib\n",
      "      - configsMLP/config_d1_t7.json\n",
      "‚úÖ D1 t+7 - SUCESSO (RMSE: 1.2542) - ‚úÖ Convergiu\n",
      "\n",
      "üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 4/12\n",
      "üéØ Treinando D1 para t+30\n",
      "üß† TREINANDO MLP - D1 para t+30\n",
      "============================================================\n",
      "üìä 1. Carregando dados D1...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-7.7183, 8.8608]\n",
      "   üìä Std: 1.3112\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.4508, 6.2790]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 30\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7839, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7839,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6271 amostras\n",
      "   ‚úÖ Teste: 1568 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (128, 64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 0.8s!\n",
      "   üìä Itera√ß√µes realizadas: 23\n",
      "   üìà Loss final: 0.396555\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 1.3258\n",
      "      MAE:  0.9866\n",
      "   üìà TESTE:\n",
      "      RMSE: 1.2511\n",
      "      MAE:  0.8440\n",
      "   ‚úÖ Sem overfitting (ratio: 0.94)\n",
      "   ‚úÖ Modelo convergiu em 23 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d1_t30.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d1_t30.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d1_t30.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [ 0.00732549 -0.03589203 -0.11714476]\n",
      "      Previs√µes (real): [-0.00370667 -0.06479139 -0.17963602]\n",
      "      Variabilidade: 0.0595\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d1_t30.joblib\n",
      "      - scalersMLP/scaler_d1_t30.joblib\n",
      "      - configsMLP/config_d1_t30.json\n",
      "‚úÖ D1 t+30 - SUCESSO (RMSE: 1.2511) - ‚úÖ Convergiu\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 5/12\n",
      "üéØ Treinando D2 para t+1\n",
      "üß† TREINANDO MLP - D2 para t+1\n",
      "============================================================\n",
      "üìä 1. Carregando dados D2...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-6.5773, 6.5198]\n",
      "   üìä Std: 1.0992\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.2595, 5.2220]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 1\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7873, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7873,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6298 amostras\n",
      "   ‚úÖ Teste: 1575 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 5.2s!\n",
      "   üìä Itera√ß√µes realizadas: 274\n",
      "   üìà Loss final: 0.004112\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.1130\n",
      "      MAE:  0.0700\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.1315\n",
      "      MAE:  0.0730\n",
      "   ‚úÖ Sem overfitting (ratio: 1.16)\n",
      "   ‚úÖ Modelo convergiu em 274 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d2_t1.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d2_t1.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d2_t1.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [ 0.47893033  0.24868025 -0.78721006]\n",
      "      Previs√µes (real): [ 0.59303173  0.30532358 -0.98906935]\n",
      "      Variabilidade: 0.7532\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d2_t1.joblib\n",
      "      - scalersMLP/scaler_d2_t1.joblib\n",
      "      - configsMLP/config_d2_t1.json\n",
      "‚úÖ D2 t+1 - SUCESSO (RMSE: 0.1315) - ‚úÖ Convergiu\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 6/12\n",
      "üéØ Treinando D2 para t+5\n",
      "üß† TREINANDO MLP - D2 para t+5\n",
      "============================================================\n",
      "üìä 1. Carregando dados D2...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-6.5773, 6.5198]\n",
      "   üìä Std: 1.0992\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.2595, 5.2220]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 5\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7869, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7869,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6295 amostras\n",
      "   ‚úÖ Teste: 1574 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 5.2s!\n",
      "   üìä Itera√ß√µes realizadas: 283\n",
      "   üìà Loss final: 0.143636\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.6720\n",
      "      MAE:  0.4836\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.6917\n",
      "      MAE:  0.4821\n",
      "   ‚úÖ Sem overfitting (ratio: 1.03)\n",
      "   ‚úÖ Modelo convergiu em 283 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d2_t5.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d2_t5.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d2_t5.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [ 0.67522853 -0.09685388  0.09509607]\n",
      "      Previs√µes (real): [ 0.83831542 -0.12643732  0.11341304]\n",
      "      Variabilidade: 0.4177\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d2_t5.joblib\n",
      "      - scalersMLP/scaler_d2_t5.joblib\n",
      "      - configsMLP/config_d2_t5.json\n",
      "‚úÖ D2 t+5 - SUCESSO (RMSE: 0.6917) - ‚úÖ Convergiu\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 7/12\n",
      "üéØ Treinando D2 para t+7\n",
      "üß† TREINANDO MLP - D2 para t+7\n",
      "============================================================\n",
      "üìä 1. Carregando dados D2...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-6.5773, 6.5198]\n",
      "   üìä Std: 1.0992\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.2595, 5.2220]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 7\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7862, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7862,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6289 amostras\n",
      "   ‚úÖ Teste: 1573 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (128, 64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 5.2s!\n",
      "   üìä Itera√ß√µes realizadas: 162\n",
      "   üìà Loss final: 0.106590\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.6161\n",
      "      MAE:  0.4294\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.7603\n",
      "      MAE:  0.5353\n",
      "   ‚úÖ Sem overfitting (ratio: 1.23)\n",
      "   ‚úÖ Modelo convergiu em 162 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d2_t7.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d2_t7.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d2_t7.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.61723124 -0.14669544  0.59498097]\n",
      "      Previs√µes (real): [-0.77667294 -0.18871666  0.73804238]\n",
      "      Variabilidade: 0.7243\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d2_t7.joblib\n",
      "      - scalersMLP/scaler_d2_t7.joblib\n",
      "      - configsMLP/config_d2_t7.json\n",
      "‚úÖ D2 t+7 - SUCESSO (RMSE: 0.7603) - ‚úÖ Convergiu\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™‚ö™ PROGRESSO: 8/12\n",
      "üéØ Treinando D2 para t+30\n",
      "üß† TREINANDO MLP - D2 para t+30\n",
      "============================================================\n",
      "üìä 1. Carregando dados D2...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-6.5773, 6.5198]\n",
      "   üìä Std: 1.0992\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.2595, 5.2220]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 30\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7839, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7839,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6271 amostras\n",
      "   ‚úÖ Teste: 1568 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (128, 64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 0.9s!\n",
      "   üìä Itera√ß√µes realizadas: 27\n",
      "   üìà Loss final: 0.384393\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 1.1266\n",
      "      MAE:  0.8482\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.9312\n",
      "      MAE:  0.6667\n",
      "   ‚úÖ Sem overfitting (ratio: 0.83)\n",
      "   ‚úÖ Modelo convergiu em 27 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d2_t30.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d2_t30.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d2_t30.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.06808248 -0.13560511 -0.11806709]\n",
      "      Previs√µes (real): [-0.09048612 -0.17485877 -0.1529442 ]\n",
      "      Variabilidade: 0.0714\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d2_t30.joblib\n",
      "      - scalersMLP/scaler_d2_t30.joblib\n",
      "      - configsMLP/config_d2_t30.json\n",
      "‚úÖ D2 t+30 - SUCESSO (RMSE: 0.9312) - ‚úÖ Convergiu\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™‚ö™ PROGRESSO: 9/12\n",
      "üéØ Treinando D3 para t+1\n",
      "üß† TREINANDO MLP - D3 para t+1\n",
      "============================================================\n",
      "üìä 1. Carregando dados D3...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-5.7485, 5.2615]\n",
      "   üìä Std: 1.0421\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.1403, 4.6939]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 1\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7873, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7873,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6298 amostras\n",
      "   ‚úÖ Teste: 1575 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 3.2s!\n",
      "   üìä Itera√ß√µes realizadas: 162\n",
      "   üìà Loss final: 0.003329\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.0865\n",
      "      MAE:  0.0559\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.0777\n",
      "      MAE:  0.0510\n",
      "   ‚úÖ Sem overfitting (ratio: 0.90)\n",
      "   ‚úÖ Modelo convergiu em 162 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d3_t1.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d3_t1.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d3_t1.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.13547794 -0.37102053 -0.64576763]\n",
      "      Previs√µes (real): [-0.14526612 -0.40896842 -0.71656224]\n",
      "      Variabilidade: 0.2918\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d3_t1.joblib\n",
      "      - scalersMLP/scaler_d3_t1.joblib\n",
      "      - configsMLP/config_d3_t1.json\n",
      "‚úÖ D3 t+1 - SUCESSO (RMSE: 0.0777) - ‚úÖ Convergiu\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™‚ö™ PROGRESSO: 10/12\n",
      "üéØ Treinando D3 para t+5\n",
      "üß† TREINANDO MLP - D3 para t+5\n",
      "============================================================\n",
      "üìä 1. Carregando dados D3...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-5.7485, 5.2615]\n",
      "   üìä Std: 1.0421\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.1403, 4.6939]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 5\n",
      "   üéØ Passo de previs√£o: 5\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7869, 5) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7869,)\n",
      "      Features: 5 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6295 amostras\n",
      "   ‚úÖ Teste: 1574 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 5.0s!\n",
      "   üìä Itera√ß√µes realizadas: 272\n",
      "   üìà Loss final: 0.075372\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.4304\n",
      "      MAE:  0.3057\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.3896\n",
      "      MAE:  0.2723\n",
      "   ‚úÖ Sem overfitting (ratio: 0.91)\n",
      "   ‚úÖ Modelo convergiu em 272 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d3_t5.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d3_t5.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d3_t5.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.54894989 -0.82111531 -1.08695814]\n",
      "      Previs√µes (real): [-0.6081697  -0.91287318 -1.21049819]\n",
      "      Variabilidade: 0.2255\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d3_t5.joblib\n",
      "      - scalersMLP/scaler_d3_t5.joblib\n",
      "      - configsMLP/config_d3_t5.json\n",
      "‚úÖ D3 t+5 - SUCESSO (RMSE: 0.3896) - ‚úÖ Convergiu\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢‚ö™ PROGRESSO: 11/12\n",
      "üéØ Treinando D3 para t+7\n",
      "üß† TREINANDO MLP - D3 para t+7\n",
      "============================================================\n",
      "üìä 1. Carregando dados D3...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-5.7485, 5.2615]\n",
      "   üìä Std: 1.0421\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.1403, 4.6939]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 7\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7862, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7862,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6289 amostras\n",
      "   ‚úÖ Teste: 1573 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (128, 64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 6.4s!\n",
      "   üìä Itera√ß√µes realizadas: 201\n",
      "   üìà Loss final: 0.049772\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 0.3592\n",
      "      MAE:  0.2604\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.3726\n",
      "      MAE:  0.2588\n",
      "   ‚úÖ Sem overfitting (ratio: 1.04)\n",
      "   ‚úÖ Modelo convergiu em 201 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d3_t7.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d3_t7.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d3_t7.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.74776904 -1.08552701 -1.02812816]\n",
      "      Previs√µes (real): [-0.83075818 -1.20889597 -1.14463493]\n",
      "      Variabilidade: 0.1404\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d3_t7.joblib\n",
      "      - scalersMLP/scaler_d3_t7.joblib\n",
      "      - configsMLP/config_d3_t7.json\n",
      "‚úÖ D3 t+7 - SUCESSO (RMSE: 0.3726) - ‚úÖ Convergiu\n",
      "\n",
      "üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢üü¢ PROGRESSO: 12/12\n",
      "üéØ Treinando D3 para t+30\n",
      "üß† TREINANDO MLP - D3 para t+30\n",
      "============================================================\n",
      "üìä 1. Carregando dados D3...\n",
      "   ‚úÖ Dados carregados: 7878 pontos\n",
      "   üìà Range: [-5.7485, 5.2615]\n",
      "   üìä Std: 1.0421\n",
      "\n",
      "üîß 2. Aplicando normaliza√ß√£o...\n",
      "   ‚úÖ Scaler: RobustScaler\n",
      "   üìà Range normalizado: [-5.1403, 4.6939]\n",
      "\n",
      "üì¶ 3. Criando dataset...\n",
      "   üìè Look_back: 10\n",
      "   üéØ Passo de previs√£o: 30\n",
      "   ‚úÖ Dataset criado:\n",
      "      X shape: (7839, 10) (apenas sequ√™ncias temporais)\n",
      "      y shape: (7839,)\n",
      "      Features: 10 (= look_back, SEM features engineering)\n",
      "\n",
      "‚úÇÔ∏è 4. Dividindo dados...\n",
      "   ‚úÖ Treino: 6271 amostras\n",
      "   ‚úÖ Teste: 1568 amostras\n",
      "\n",
      "üß† 5. Configurando MLP...\n",
      "   üìã Par√¢metros MLP:\n",
      "      Arquitetura: (128, 64, 32, 16)\n",
      "      Ativa√ß√£o: relu\n",
      "      Solver: adam\n",
      "      Learning rate: 0.001\n",
      "      Regulariza√ß√£o: 0.001\n",
      "      Max √©pocas: 500\n",
      "      Early stopping: True\n",
      "\n",
      "üöÄ 6. Treinando modelo...\n",
      "   ‚úÖ Treinamento conclu√≠do em 1.8s!\n",
      "   üìä Itera√ß√µes realizadas: 57\n",
      "   üìà Loss final: 0.423999\n",
      "\n",
      "üìä 7. Avaliando performance...\n",
      "   üìà TREINO:\n",
      "      RMSE: 1.0541\n",
      "      MAE:  0.7858\n",
      "   üìà TESTE:\n",
      "      RMSE: 0.8461\n",
      "      MAE:  0.6074\n",
      "   ‚úÖ Sem overfitting (ratio: 0.80)\n",
      "   ‚úÖ Modelo convergiu em 57 itera√ß√µes\n",
      "\n",
      "üíæ 8. Salvando arquivos...\n",
      "   ‚úÖ Modelo salvo: modelosMLP/mlp_d3_t30.joblib\n",
      "   ‚úÖ Scaler salvo: scalersMLP/scaler_d3_t30.joblib\n",
      "   ‚úÖ Config salva: configsMLP/config_d3_t30.json\n",
      "\n",
      "üß™ 9. Teste de sanidade...\n",
      "   ‚úÖ Modelo carregado e testado:\n",
      "      Amostras teste: 5\n",
      "      Previs√µes (normalizado): [-0.09859281  0.04034503  0.04981435]\n",
      "      Previs√µes (real): [-0.10397128  0.05157693  0.06217833]\n",
      "      Variabilidade: 0.0609\n",
      "\n",
      "üéâ TREINAMENTO MLP CONCLU√çDO COM SUCESSO!\n",
      "   üìÅ Arquivos salvos:\n",
      "      - modelosMLP/mlp_d3_t30.joblib\n",
      "      - scalersMLP/scaler_d3_t30.joblib\n",
      "      - configsMLP/config_d3_t30.json\n",
      "‚úÖ D3 t+30 - SUCESSO (RMSE: 0.8461) - ‚úÖ Convergiu\n",
      "\n",
      "======================================================================\n",
      "üìä RESUMO FINAL DO TREINAMENTO MLP\n",
      "======================================================================\n",
      "‚è±Ô∏è Tempo total: 0.7 minutos\n",
      "Componente   Horizonte  RMSE     MAE      Convergiu  Status    \n",
      "--------------------------------------------------------------------------------\n",
      "D1           t+1        0.2813   0.1342   Sim        OK        \n",
      "D1           t+5        1.2700   0.8554   Sim        OK        \n",
      "D1           t+7        1.2542   0.8406   Sim        OK        \n",
      "D1           t+30       1.2511   0.8440   Sim        OK        \n",
      "D2           t+1        0.1315   0.0730   Sim        OK        \n",
      "D2           t+5        0.6917   0.4821   Sim        OK        \n",
      "D2           t+7        0.7603   0.5353   Sim        OK        \n",
      "D2           t+30       0.9312   0.6667   Sim        OK        \n",
      "D3           t+1        0.0777   0.0510   Sim        OK        \n",
      "D3           t+5        0.3896   0.2723   Sim        OK        \n",
      "D3           t+7        0.3726   0.2588   Sim        OK        \n",
      "D3           t+30       0.8461   0.6074   Sim        OK        \n",
      "\n",
      "üìä ESTAT√çSTICAS:\n",
      "   ‚úÖ Sucessos: 12\n",
      "   ‚ùå Falhas: 0\n",
      "   ‚ö†Ô∏è N√£o convergiram: 0\n",
      "   üìà Taxa de sucesso: 100.0%\n",
      "\n",
      "üíæ Resumo salvo: configsMLP/resumo_treinamento_mlp.json\n",
      "\n",
      "üéâ TODOS OS MODELOS MLP TREINADOS COM SUCESSO!\n"
     ]
    }
   ],
   "source": [
    "resultados = treinar_todos_componentes_mlp([1, 5, 7, 30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
