{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6148f558",
   "metadata": {},
   "source": [
    "## Cรณdigo final consolidado: LSTM com HPO + linearidade + robustez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "945d8224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "๐ Treinando LSTM para t+1 com look_back=5\n",
      "Reloading Tuner from tuner_results\\lstm_t1\\tuner0.json\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0135 - mae: 0.0633 - val_loss: 0.0105 - val_mae: 0.0507\n",
      "Epoch 2/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0110 - mae: 0.0562 - val_loss: 0.0092 - val_mae: 0.0520\n",
      "Epoch 3/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0526 - val_loss: 0.0077 - val_mae: 0.0464\n",
      "Epoch 4/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - mae: 0.0467 - val_loss: 0.0064 - val_mae: 0.0437\n",
      "Epoch 5/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - mae: 0.0403 - val_loss: 0.0052 - val_mae: 0.0412\n",
      "Epoch 6/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - mae: 0.0367 - val_loss: 0.0045 - val_mae: 0.0480\n",
      "Epoch 7/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0369 - val_loss: 0.0030 - val_mae: 0.0287\n",
      "Epoch 8/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0326 - val_loss: 0.0024 - val_mae: 0.0262\n",
      "Epoch 9/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - mae: 0.0249 - val_loss: 0.0019 - val_mae: 0.0240\n",
      "Epoch 10/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - mae: 0.0251 - val_loss: 0.0015 - val_mae: 0.0248\n",
      "Epoch 11/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 0.0010 - val_mae: 0.0214\n",
      "Epoch 12/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 6.7144e-04 - val_mae: 0.0204\n",
      "Epoch 13/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4355e-04 - mae: 0.0247 - val_loss: 3.6479e-04 - val_mae: 0.0209\n",
      "Epoch 14/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8115e-04 - mae: 0.0235 - val_loss: 3.9430e-04 - val_mae: 0.0216\n",
      "Epoch 15/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1453e-04 - mae: 0.0267 - val_loss: 4.8733e-04 - val_mae: 0.0258\n",
      "Epoch 16/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9488e-04 - mae: 0.0242 - val_loss: 4.3306e-04 - val_mae: 0.0240\n",
      "Epoch 17/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1562e-04 - mae: 0.0225 - val_loss: 5.1343e-04 - val_mae: 0.0268\n",
      "Epoch 18/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2244e-04 - mae: 0.0224 - val_loss: 3.6742e-04 - val_mae: 0.0213\n",
      "Epoch 19/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4985e-04 - mae: 0.0235 - val_loss: 5.3627e-04 - val_mae: 0.0278\n",
      "Epoch 20/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7009e-04 - mae: 0.0243 - val_loss: 9.4935e-04 - val_mae: 0.0390\n",
      "Epoch 21/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0499e-04 - mae: 0.0272 - val_loss: 4.8701e-04 - val_mae: 0.0262\n",
      "Epoch 22/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5589e-04 - mae: 0.0209 - val_loss: 5.9503e-04 - val_mae: 0.0297\n",
      "Epoch 23/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0798e-04 - mae: 0.0255 - val_loss: 3.0660e-04 - val_mae: 0.0194\n",
      "Epoch 24/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2913e-04 - mae: 0.0222 - val_loss: 3.6583e-04 - val_mae: 0.0219\n",
      "Epoch 25/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5287e-04 - mae: 0.0199 - val_loss: 3.4155e-04 - val_mae: 0.0211\n",
      "Epoch 26/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9336e-04 - mae: 0.0218 - val_loss: 3.0239e-04 - val_mae: 0.0195\n",
      "Epoch 27/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4421e-04 - mae: 0.0202 - val_loss: 3.0170e-04 - val_mae: 0.0194\n",
      "Epoch 28/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0817e-04 - mae: 0.0190 - val_loss: 2.9488e-04 - val_mae: 0.0194\n",
      "Epoch 29/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5959e-04 - mae: 0.0206 - val_loss: 3.0125e-04 - val_mae: 0.0197\n",
      "Epoch 30/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9122e-04 - mae: 0.0182 - val_loss: 3.8511e-04 - val_mae: 0.0231\n",
      "Epoch 31/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2796e-04 - mae: 0.0197 - val_loss: 3.6211e-04 - val_mae: 0.0221\n",
      "Epoch 32/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7170e-04 - mae: 0.0179 - val_loss: 3.3772e-04 - val_mae: 0.0213\n",
      "Epoch 33/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6639e-04 - mae: 0.0177 - val_loss: 2.7166e-04 - val_mae: 0.0186\n",
      "Epoch 34/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0642e-04 - mae: 0.0192 - val_loss: 2.7446e-04 - val_mae: 0.0187\n",
      "Epoch 35/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0738e-04 - mae: 0.0186 - val_loss: 2.5839e-04 - val_mae: 0.0181\n",
      "Epoch 36/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3771e-04 - mae: 0.0163 - val_loss: 2.4857e-04 - val_mae: 0.0178\n",
      "Epoch 37/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2868e-04 - mae: 0.0164 - val_loss: 2.5647e-04 - val_mae: 0.0182\n",
      "Epoch 38/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2328e-04 - mae: 0.0159 - val_loss: 2.5133e-04 - val_mae: 0.0180\n",
      "Epoch 39/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2196e-04 - mae: 0.0158 - val_loss: 2.3582e-04 - val_mae: 0.0177\n",
      "Epoch 40/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9526e-04 - mae: 0.0187 - val_loss: 2.0900e-04 - val_mae: 0.0164\n",
      "Epoch 41/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8608e-04 - mae: 0.0143 - val_loss: 2.5351e-04 - val_mae: 0.0183\n",
      "Epoch 42/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8766e-04 - mae: 0.0145 - val_loss: 2.0541e-04 - val_mae: 0.0164\n",
      "Epoch 43/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8234e-04 - mae: 0.0144 - val_loss: 2.1914e-04 - val_mae: 0.0169\n",
      "Epoch 44/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6809e-04 - mae: 0.0136 - val_loss: 1.9978e-04 - val_mae: 0.0161\n",
      "Epoch 45/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0274e-04 - mae: 0.0156 - val_loss: 2.9717e-04 - val_mae: 0.0203\n",
      "Epoch 46/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8012e-04 - mae: 0.0143 - val_loss: 2.3472e-04 - val_mae: 0.0177\n",
      "Epoch 47/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7670e-04 - mae: 0.0144 - val_loss: 1.8637e-04 - val_mae: 0.0156\n",
      "Epoch 48/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8177e-04 - mae: 0.0144 - val_loss: 3.7437e-04 - val_mae: 0.0239\n",
      "Epoch 49/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8265e-04 - mae: 0.0148 - val_loss: 1.6582e-04 - val_mae: 0.0146\n",
      "Epoch 50/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3938e-04 - mae: 0.0122 - val_loss: 2.1866e-04 - val_mae: 0.0168\n",
      "Epoch 51/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4163e-04 - mae: 0.0172 - val_loss: 2.0125e-04 - val_mae: 0.0161\n",
      "Epoch 52/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3087e-04 - mae: 0.0117 - val_loss: 3.3695e-04 - val_mae: 0.0227\n",
      "Epoch 53/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9386e-04 - mae: 0.0150 - val_loss: 1.4115e-04 - val_mae: 0.0130\n",
      "Epoch 54/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3534e-04 - mae: 0.0122 - val_loss: 1.5634e-04 - val_mae: 0.0140\n",
      "Epoch 55/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5482e-04 - mae: 0.0133 - val_loss: 1.5002e-04 - val_mae: 0.0139\n",
      "Epoch 56/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5687e-04 - mae: 0.0134 - val_loss: 1.5339e-04 - val_mae: 0.0139\n",
      "Epoch 57/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1865e-04 - mae: 0.0111 - val_loss: 2.0397e-04 - val_mae: 0.0167\n",
      "Epoch 58/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2300e-04 - mae: 0.0114 - val_loss: 1.5384e-04 - val_mae: 0.0139\n",
      "Epoch 59/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2483e-04 - mae: 0.0113 - val_loss: 1.2169e-04 - val_mae: 0.0123\n",
      "Epoch 60/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2538e-04 - mae: 0.0116 - val_loss: 1.2456e-04 - val_mae: 0.0126\n",
      "Epoch 61/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0816e-04 - mae: 0.0107 - val_loss: 1.9286e-04 - val_mae: 0.0165\n",
      "Epoch 62/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5799e-04 - mae: 0.0131 - val_loss: 2.7956e-04 - val_mae: 0.0210\n",
      "Epoch 63/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4347e-04 - mae: 0.0130 - val_loss: 1.9822e-04 - val_mae: 0.0169\n",
      "Epoch 64/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3665e-04 - mae: 0.0123 - val_loss: 8.8233e-05 - val_mae: 0.0098\n",
      "Epoch 65/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0136e-04 - mae: 0.0104 - val_loss: 9.6355e-05 - val_mae: 0.0108\n",
      "Epoch 66/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1358e-04 - mae: 0.0111 - val_loss: 8.7130e-05 - val_mae: 0.0100\n",
      "Epoch 67/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9737e-05 - mae: 0.0102 - val_loss: 1.0267e-04 - val_mae: 0.0114\n",
      "Epoch 68/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7540e-05 - mae: 0.0102 - val_loss: 1.0948e-04 - val_mae: 0.0111\n",
      "Epoch 69/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3415e-04 - mae: 0.0122 - val_loss: 1.5835e-04 - val_mae: 0.0151\n",
      "Epoch 70/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0052e-04 - mae: 0.0107 - val_loss: 7.7040e-05 - val_mae: 0.0092\n",
      "Epoch 71/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1338e-04 - mae: 0.0111 - val_loss: 1.3441e-04 - val_mae: 0.0137\n",
      "Epoch 72/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1355e-04 - mae: 0.0112 - val_loss: 7.5260e-05 - val_mae: 0.0090\n",
      "Epoch 73/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1443e-04 - mae: 0.0112 - val_loss: 7.8504e-05 - val_mae: 0.0094\n",
      "Epoch 74/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0521e-04 - mae: 0.0108 - val_loss: 7.6275e-05 - val_mae: 0.0091\n",
      "Epoch 75/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1590e-04 - mae: 0.0115 - val_loss: 1.3989e-04 - val_mae: 0.0137\n",
      "Epoch 76/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3533e-04 - mae: 0.0120 - val_loss: 6.9539e-05 - val_mae: 0.0087\n",
      "Epoch 77/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8142e-05 - mae: 0.0101 - val_loss: 6.1539e-05 - val_mae: 0.0080\n",
      "Epoch 78/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5486e-05 - mae: 0.0101 - val_loss: 8.5411e-05 - val_mae: 0.0097\n",
      "Epoch 79/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9718e-05 - mae: 0.0096 - val_loss: 8.2607e-05 - val_mae: 0.0102\n",
      "Epoch 80/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6374e-05 - mae: 0.0096 - val_loss: 9.9610e-05 - val_mae: 0.0114\n",
      "Epoch 81/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0170e-04 - mae: 0.0102 - val_loss: 6.5113e-05 - val_mae: 0.0086\n",
      "Epoch 82/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0103e-04 - mae: 0.0104 - val_loss: 1.2548e-04 - val_mae: 0.0130\n",
      "Epoch 83/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1067e-04 - mae: 0.0114 - val_loss: 9.1284e-05 - val_mae: 0.0109\n",
      "Epoch 84/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0789e-04 - mae: 0.0110 - val_loss: 1.5866e-04 - val_mae: 0.0155\n",
      "Epoch 85/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1076e-04 - mae: 0.0113 - val_loss: 8.6958e-05 - val_mae: 0.0099\n",
      "Epoch 86/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6797e-05 - mae: 0.0104 - val_loss: 5.7254e-05 - val_mae: 0.0076\n",
      "Epoch 87/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6791e-05 - mae: 0.0094 - val_loss: 5.5346e-05 - val_mae: 0.0075\n",
      "Epoch 88/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2255e-05 - mae: 0.0087 - val_loss: 6.4029e-05 - val_mae: 0.0085\n",
      "Epoch 89/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8875e-05 - mae: 0.0090 - val_loss: 2.4611e-04 - val_mae: 0.0188\n",
      "Epoch 90/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3949e-04 - mae: 0.0173 - val_loss: 2.4836e-04 - val_mae: 0.0201\n",
      "Epoch 91/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5119e-04 - mae: 0.0136 - val_loss: 7.7610e-05 - val_mae: 0.0098\n",
      "Epoch 92/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0552e-05 - mae: 0.0091 - val_loss: 5.6116e-05 - val_mae: 0.0075\n",
      "Epoch 93/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4192e-05 - mae: 0.0095 - val_loss: 5.5177e-05 - val_mae: 0.0075\n",
      "Epoch 94/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8446e-05 - mae: 0.0091 - val_loss: 5.2328e-05 - val_mae: 0.0069\n",
      "Epoch 95/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8877e-05 - mae: 0.0091 - val_loss: 5.0114e-05 - val_mae: 0.0072\n",
      "Epoch 96/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8459e-05 - mae: 0.0092 - val_loss: 1.1068e-04 - val_mae: 0.0125\n",
      "Epoch 97/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9144e-05 - mae: 0.0106 - val_loss: 1.1779e-04 - val_mae: 0.0127\n",
      "Epoch 98/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3030e-05 - mae: 0.0103 - val_loss: 6.1122e-05 - val_mae: 0.0080\n",
      "Epoch 99/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2256e-05 - mae: 0.0095 - val_loss: 4.8507e-05 - val_mae: 0.0069\n",
      "Epoch 100/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6006e-05 - mae: 0.0090 - val_loss: 4.7986e-05 - val_mae: 0.0066\n",
      "โ Modelo salvo: lstm_a3_t1.keras\n",
      "\n",
      "๐ Treinando LSTM para t+5 com look_back=5\n",
      "Reloading Tuner from tuner_results\\lstm_t5\\tuner0.json\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0182 - mae: 0.0998 - val_loss: 0.0180 - val_mae: 0.1162\n",
      "Epoch 2/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0159 - mae: 0.0990 - val_loss: 0.0151 - val_mae: 0.1047\n",
      "Epoch 3/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0149 - mae: 0.0969 - val_loss: 0.0149 - val_mae: 0.1113\n",
      "Epoch 4/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0969 - val_loss: 0.0137 - val_mae: 0.1083\n",
      "Epoch 5/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0129 - mae: 0.0956 - val_loss: 0.0138 - val_mae: 0.1135\n",
      "Epoch 6/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0914 - val_loss: 0.0130 - val_mae: 0.1122\n",
      "Epoch 7/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0110 - mae: 0.0927 - val_loss: 0.0122 - val_mae: 0.1104\n",
      "Epoch 8/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0924 - val_loss: 0.0119 - val_mae: 0.1119\n",
      "Epoch 9/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - mae: 0.0946 - val_loss: 0.0103 - val_mae: 0.1046\n",
      "Epoch 10/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0910 - val_loss: 0.0110 - val_mae: 0.1121\n",
      "Epoch 11/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - mae: 0.0856 - val_loss: 0.0120 - val_mae: 0.1218\n",
      "Epoch 12/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - mae: 0.0863 - val_loss: 0.0117 - val_mae: 0.1223\n",
      "Epoch 13/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - mae: 0.0901 - val_loss: 0.0102 - val_mae: 0.1145\n",
      "Epoch 14/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - mae: 0.0857 - val_loss: 0.0095 - val_mae: 0.1118\n",
      "Epoch 15/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - mae: 0.0886 - val_loss: 0.0096 - val_mae: 0.1144\n",
      "Epoch 16/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - mae: 0.0883 - val_loss: 0.0096 - val_mae: 0.1154\n",
      "Epoch 17/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - mae: 0.0883 - val_loss: 0.0078 - val_mae: 0.1033\n",
      "Epoch 18/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0852 - val_loss: 0.0078 - val_mae: 0.1034\n",
      "Epoch 19/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - mae: 0.0817 - val_loss: 0.0071 - val_mae: 0.0982\n",
      "Epoch 20/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - mae: 0.0817 - val_loss: 0.0079 - val_mae: 0.1041\n",
      "Epoch 21/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0798 - val_loss: 0.0076 - val_mae: 0.1017\n",
      "Epoch 22/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - mae: 0.0791 - val_loss: 0.0079 - val_mae: 0.1041\n",
      "Epoch 23/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - mae: 0.0780 - val_loss: 0.0073 - val_mae: 0.1001\n",
      "Epoch 24/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - mae: 0.0774 - val_loss: 0.0071 - val_mae: 0.0979\n",
      "Epoch 25/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - mae: 0.0777 - val_loss: 0.0059 - val_mae: 0.0886\n",
      "Epoch 26/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - mae: 0.0794 - val_loss: 0.0061 - val_mae: 0.0901\n",
      "Epoch 27/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - mae: 0.0776 - val_loss: 0.0070 - val_mae: 0.0985\n",
      "Epoch 28/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0817 - val_loss: 0.0058 - val_mae: 0.0879\n",
      "Epoch 29/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - mae: 0.0747 - val_loss: 0.0071 - val_mae: 0.0997\n",
      "Epoch 30/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0809 - val_loss: 0.0054 - val_mae: 0.0846\n",
      "Epoch 31/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0794 - val_loss: 0.0064 - val_mae: 0.0929\n",
      "Epoch 32/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0754 - val_loss: 0.0064 - val_mae: 0.0937\n",
      "Epoch 33/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - mae: 0.0760 - val_loss: 0.0051 - val_mae: 0.0819\n",
      "Epoch 34/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0785 - val_loss: 0.0051 - val_mae: 0.0813\n",
      "Epoch 35/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - mae: 0.0732 - val_loss: 0.0053 - val_mae: 0.0835\n",
      "Epoch 36/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - mae: 0.0732 - val_loss: 0.0069 - val_mae: 0.0987\n",
      "Epoch 37/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0768 - val_loss: 0.0064 - val_mae: 0.0938\n",
      "Epoch 38/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 - mae: 0.0796 - val_loss: 0.0055 - val_mae: 0.0857\n",
      "Epoch 39/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - mae: 0.0733 - val_loss: 0.0058 - val_mae: 0.0878\n",
      "Epoch 40/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - mae: 0.0740 - val_loss: 0.0056 - val_mae: 0.0871\n",
      "Epoch 41/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - mae: 0.0733 - val_loss: 0.0059 - val_mae: 0.0895\n",
      "Epoch 42/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0755 - val_loss: 0.0058 - val_mae: 0.0880\n",
      "Epoch 43/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - mae: 0.0773 - val_loss: 0.0055 - val_mae: 0.0860\n",
      "Epoch 44/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - mae: 0.0718 - val_loss: 0.0059 - val_mae: 0.0892\n",
      "โ Modelo salvo: lstm_a3_t5.keras\n",
      "\n",
      "๐ Treinando LSTM para t+7 com look_back=10\n",
      "Reloading Tuner from tuner_results\\lstm_t7\\tuner0.json\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0290 - mae: 0.1175 - val_loss: 0.0288 - val_mae: 0.1428\n",
      "Epoch 2/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0239 - mae: 0.1110 - val_loss: 0.0250 - val_mae: 0.1417\n",
      "Epoch 3/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0203 - mae: 0.1121 - val_loss: 0.0194 - val_mae: 0.1270\n",
      "Epoch 4/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0158 - mae: 0.1018 - val_loss: 0.0166 - val_mae: 0.1245\n",
      "Epoch 5/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0148 - mae: 0.1085 - val_loss: 0.0170 - val_mae: 0.1369\n",
      "Epoch 6/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.1051 - val_loss: 0.0135 - val_mae: 0.1212\n",
      "Epoch 7/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.1031 - val_loss: 0.0171 - val_mae: 0.1458\n",
      "Epoch 8/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.1041 - val_loss: 0.0154 - val_mae: 0.1386\n",
      "Epoch 9/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0976 - val_loss: 0.0115 - val_mae: 0.1170\n",
      "Epoch 10/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.1027 - val_loss: 0.0119 - val_mae: 0.1220\n",
      "Epoch 11/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.1023 - val_loss: 0.0093 - val_mae: 0.1066\n",
      "Epoch 12/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0090 - mae: 0.0985 - val_loss: 0.0086 - val_mae: 0.1030\n",
      "Epoch 13/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0092 - val_mae: 0.1101\n",
      "Epoch 14/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - mae: 0.0959 - val_loss: 0.0083 - val_mae: 0.1056\n",
      "Epoch 15/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - mae: 0.0993 - val_loss: 0.0068 - val_mae: 0.0934\n",
      "Epoch 16/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - mae: 0.0978 - val_loss: 0.0070 - val_mae: 0.0957\n",
      "Epoch 17/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - mae: 0.1001 - val_loss: 0.0074 - val_mae: 0.0990\n",
      "Epoch 18/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.1015 - val_loss: 0.0084 - val_mae: 0.1068\n",
      "Epoch 19/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - mae: 0.1018 - val_loss: 0.0102 - val_mae: 0.1212\n",
      "Epoch 20/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - mae: 0.0973 - val_loss: 0.0064 - val_mae: 0.0909\n",
      "Epoch 21/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - mae: 0.0968 - val_loss: 0.0081 - val_mae: 0.1042\n",
      "Epoch 22/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - mae: 0.0961 - val_loss: 0.0077 - val_mae: 0.1016\n",
      "Epoch 23/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - mae: 0.0954 - val_loss: 0.0064 - val_mae: 0.0906\n",
      "Epoch 24/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0966 - val_loss: 0.0077 - val_mae: 0.1017\n",
      "Epoch 25/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0068 - mae: 0.0910 - val_loss: 0.0083 - val_mae: 0.1062\n",
      "Epoch 26/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - mae: 0.0922 - val_loss: 0.0072 - val_mae: 0.0978\n",
      "Epoch 27/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0070 - mae: 0.0898 - val_loss: 0.0074 - val_mae: 0.0996\n",
      "Epoch 28/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - mae: 0.0918 - val_loss: 0.0058 - val_mae: 0.0866\n",
      "Epoch 29/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - mae: 0.0918 - val_loss: 0.0066 - val_mae: 0.0936\n",
      "Epoch 30/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - mae: 0.0941 - val_loss: 0.0058 - val_mae: 0.0865\n",
      "Epoch 31/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - mae: 0.0866 - val_loss: 0.0061 - val_mae: 0.0893\n",
      "Epoch 32/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - mae: 0.0902 - val_loss: 0.0052 - val_mae: 0.0806\n",
      "Epoch 33/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - mae: 0.0886 - val_loss: 0.0058 - val_mae: 0.0862\n",
      "Epoch 34/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - mae: 0.0897 - val_loss: 0.0062 - val_mae: 0.0900\n",
      "Epoch 35/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - mae: 0.0906 - val_loss: 0.0050 - val_mae: 0.0787\n",
      "Epoch 36/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - mae: 0.0884 - val_loss: 0.0056 - val_mae: 0.0852\n",
      "Epoch 37/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - mae: 0.0895 - val_loss: 0.0049 - val_mae: 0.0777\n",
      "Epoch 38/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - mae: 0.0875 - val_loss: 0.0062 - val_mae: 0.0903\n",
      "Epoch 39/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - mae: 0.0863 - val_loss: 0.0052 - val_mae: 0.0816\n",
      "Epoch 40/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0852 - val_loss: 0.0050 - val_mae: 0.0794\n",
      "Epoch 41/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - mae: 0.0831 - val_loss: 0.0063 - val_mae: 0.0918\n",
      "Epoch 42/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - mae: 0.0884 - val_loss: 0.0050 - val_mae: 0.0794\n",
      "Epoch 43/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - mae: 0.0865 - val_loss: 0.0051 - val_mae: 0.0800\n",
      "Epoch 44/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - mae: 0.0810 - val_loss: 0.0051 - val_mae: 0.0800\n",
      "Epoch 45/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0869 - val_loss: 0.0058 - val_mae: 0.0868\n",
      "Epoch 46/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - mae: 0.0809 - val_loss: 0.0052 - val_mae: 0.0815\n",
      "Epoch 47/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - mae: 0.0888 - val_loss: 0.0047 - val_mae: 0.0769\n",
      "Epoch 48/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - mae: 0.0890 - val_loss: 0.0055 - val_mae: 0.0845\n",
      "Epoch 49/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - mae: 0.0835 - val_loss: 0.0048 - val_mae: 0.0777\n",
      "Epoch 50/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - mae: 0.0854 - val_loss: 0.0054 - val_mae: 0.0840\n",
      "Epoch 51/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0792 - val_loss: 0.0053 - val_mae: 0.0823\n",
      "Epoch 52/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - mae: 0.0835 - val_loss: 0.0047 - val_mae: 0.0768\n",
      "Epoch 53/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0845 - val_loss: 0.0050 - val_mae: 0.0794\n",
      "Epoch 54/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0863 - val_loss: 0.0051 - val_mae: 0.0808\n",
      "Epoch 55/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0817 - val_loss: 0.0049 - val_mae: 0.0785\n",
      "Epoch 56/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0797 - val_loss: 0.0042 - val_mae: 0.0713\n",
      "Epoch 57/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - mae: 0.0823 - val_loss: 0.0052 - val_mae: 0.0817\n",
      "Epoch 58/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - mae: 0.0830 - val_loss: 0.0048 - val_mae: 0.0782\n",
      "Epoch 59/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0803 - val_loss: 0.0042 - val_mae: 0.0715\n",
      "Epoch 60/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - mae: 0.0797 - val_loss: 0.0047 - val_mae: 0.0771\n",
      "Epoch 61/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0800 - val_loss: 0.0046 - val_mae: 0.0761\n",
      "Epoch 62/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - mae: 0.0811 - val_loss: 0.0047 - val_mae: 0.0764\n",
      "Epoch 63/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0806 - val_loss: 0.0045 - val_mae: 0.0745\n",
      "Epoch 64/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0824 - val_loss: 0.0044 - val_mae: 0.0737\n",
      "Epoch 65/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - mae: 0.0772 - val_loss: 0.0051 - val_mae: 0.0807\n",
      "Epoch 66/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - mae: 0.0822 - val_loss: 0.0052 - val_mae: 0.0818\n",
      "โ Modelo salvo: lstm_a3_t7.keras\n",
      "\n",
      "๐ Treinando LSTM para t+30 com look_back=10\n",
      "Reloading Tuner from tuner_results\\lstm_t30\\tuner0.json\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0236 - mae: 0.1092 - val_loss: 0.0244 - val_mae: 0.1304\n",
      "Epoch 2/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0205 - mae: 0.1047 - val_loss: 0.0271 - val_mae: 0.1563\n",
      "Epoch 3/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0189 - mae: 0.1048 - val_loss: 0.0244 - val_mae: 0.1507\n",
      "Epoch 4/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0168 - mae: 0.1013 - val_loss: 0.0217 - val_mae: 0.1441\n",
      "Epoch 5/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0151 - mae: 0.0993 - val_loss: 0.0204 - val_mae: 0.1448\n",
      "Epoch 6/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0140 - mae: 0.1039 - val_loss: 0.0191 - val_mae: 0.1449\n",
      "Epoch 7/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0129 - mae: 0.1048 - val_loss: 0.0161 - val_mae: 0.1353\n",
      "Epoch 8/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0119 - mae: 0.1044 - val_loss: 0.0182 - val_mae: 0.1511\n",
      "Epoch 9/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0110 - mae: 0.1052 - val_loss: 0.0155 - val_mae: 0.1401\n",
      "Epoch 10/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0105 - mae: 0.1058 - val_loss: 0.0154 - val_mae: 0.1439\n",
      "Epoch 11/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0093 - mae: 0.1032 - val_loss: 0.0155 - val_mae: 0.1481\n",
      "Epoch 12/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0084 - mae: 0.1010 - val_loss: 0.0158 - val_mae: 0.1494\n",
      "Epoch 13/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.1017 - val_loss: 0.0153 - val_mae: 0.1466\n",
      "Epoch 14/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.1029 - val_loss: 0.0175 - val_mae: 0.1585\n",
      "Epoch 15/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.1010 - val_loss: 0.0197 - val_mae: 0.1691\n",
      "Epoch 16/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.1014 - val_loss: 0.0187 - val_mae: 0.1643\n",
      "Epoch 17/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0089 - mae: 0.1041 - val_loss: 0.0171 - val_mae: 0.1562\n",
      "Epoch 18/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.1021 - val_loss: 0.0184 - val_mae: 0.1626\n",
      "Epoch 19/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0082 - mae: 0.0998 - val_loss: 0.0180 - val_mae: 0.1609\n",
      "Epoch 20/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.1010 - val_loss: 0.0140 - val_mae: 0.1401\n",
      "Epoch 21/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.1012 - val_loss: 0.0208 - val_mae: 0.1745\n",
      "Epoch 22/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.1004 - val_loss: 0.0153 - val_mae: 0.1473\n",
      "Epoch 23/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0089 - mae: 0.1039 - val_loss: 0.0184 - val_mae: 0.1625\n",
      "Epoch 24/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0999 - val_loss: 0.0195 - val_mae: 0.1682\n",
      "Epoch 25/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.1033 - val_loss: 0.0146 - val_mae: 0.1434\n",
      "Epoch 26/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0082 - mae: 0.1006 - val_loss: 0.0168 - val_mae: 0.1548\n",
      "Epoch 27/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0994 - val_loss: 0.0173 - val_mae: 0.1573\n",
      "Epoch 28/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.1019 - val_loss: 0.0154 - val_mae: 0.1475\n",
      "Epoch 29/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0088 - mae: 0.1042 - val_loss: 0.0144 - val_mae: 0.1423\n",
      "Epoch 30/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mโโโโโโโโโโโโโโโโโโโโ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0089 - mae: 0.1047 - val_loss: 0.0170 - val_mae: 0.1558\n",
      "โ Modelo salvo: lstm_a3_t30.keras\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Flatten, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# === Funรงรฃo para criar dataset multi-step ===\n",
    "def criar_dataset_multi_step(series, look_back=10, passo=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - look_back - passo + 1):\n",
    "        X.append(series[i:i+look_back])\n",
    "        y.append(series[i+look_back+passo-1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# === Funรงรฃo geradora de modelo com look_back fixado ===\n",
    "def get_build_model(look_back):\n",
    "    def build_model(hp):\n",
    "        inputs = Input(shape=(look_back, 1))\n",
    "        lstm_out = LSTM(\n",
    "            units=hp.Int('lstm_units', min_value=32, max_value=128, step=32),\n",
    "            return_sequences=False\n",
    "        )(inputs)\n",
    "\n",
    "        flattened = Flatten()(inputs)\n",
    "        normalized = BatchNormalization()(flattened)\n",
    "        linear_weights = Dense(\n",
    "            1, use_bias=False,\n",
    "            kernel_regularizer=l1_l2(l1=0.01, l2=0.01),\n",
    "            name=\"linear_combination\"\n",
    "        )(normalized)\n",
    "\n",
    "        combined = Concatenate()([lstm_out, linear_weights])\n",
    "        output = Dense(1)(combined)\n",
    "\n",
    "        model = Model(inputs, output)\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss=tf.keras.losses.Huber(delta=1.0),\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        return model\n",
    "    return build_model\n",
    "\n",
    "# === Loop para cada horizonte de previsรฃo ===\n",
    "a3_df = pd.read_csv(\"A3_component.csv\")\n",
    "a3 = a3_df[\"A3\"].values.reshape(-1, 1)\n",
    "\n",
    "for passo in [1, 5, 7, 30]:\n",
    "    look_back = 5 if passo <= 5 else 10\n",
    "    print(f\"\\n๐ Treinando LSTM para t+{passo} com look_back={look_back}\")\n",
    "\n",
    "    # Normalizaรงรฃo\n",
    "    scaler = MinMaxScaler()\n",
    "    a3_scaled = scaler.fit_transform(a3)\n",
    "    joblib.dump(scaler, f\"scaler_A3_t{passo}.joblib\")\n",
    "\n",
    "    # Criar dataset\n",
    "    X, y = criar_dataset_multi_step(a3_scaled, look_back=look_back, passo=passo)\n",
    "\n",
    "    # Tuner\n",
    "    tuner = RandomSearch(\n",
    "        get_build_model(look_back),\n",
    "        objective='val_loss',\n",
    "        max_trials=5,\n",
    "        executions_per_trial=1,\n",
    "        directory='tuner_results',\n",
    "        project_name=f'lstm_t{passo}'\n",
    "    )\n",
    "\n",
    "    # Validaรงรฃo cruzada temporal\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        tuner.search(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "            verbose=0\n",
    "        )\n",
    "        break  # usar apenas a 1ยช divisรฃo do TimeSeriesSplit\n",
    "\n",
    "    # Treinar melhor modelo\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    best_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Salvar modelo\n",
    "    best_model.save(f\"lstm_a3_t{passo}.keras\")\n",
    "    print(f\"โ Modelo salvo: lstm_a3_t{passo}.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
